{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d85531aa",
   "metadata": {},
   "source": [
    "# Building TF-IDF from Scratch\n",
    "In this notebook, we will implement **Term Frequency - Inverse Document Frequency (TF-IDF)** from scratch using Python. \n",
    "This is a fundamental technique in Natural Language Processing (NLP) for converting text data into numerical vectors.\n",
    "\n",
    "### Goals\n",
    "1. Implement **TF (Term Frequency)**.\n",
    "2. Implement **IDF (Inverse Document Frequency)**.\n",
    "3. Combine them to create **TF-IDF**.\n",
    "4. Compare our results with `sklearn`.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94f8ef80",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import math\n",
    "import numpy as np\n",
    "\n",
    "# Sample Corpus\n",
    "corpus = [\n",
    "    \"the cat sat on the mat\",\n",
    "    \"the dog sat on the log\",\n",
    "    \"cats and dogs are great\"\n",
    "]\n",
    "print(\"Corpus:\", corpus)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "515ab307",
   "metadata": {},
   "source": [
    "## 1. Term Frequency (TF)\n",
    "\n",
    "**Term Frequency** measures how frequently a term appears in a document. \n",
    "\n",
    "### Formula\n",
    "$$\n",
    "TF(t, d) = \\frac{\\text{count of term } t \\text{ in document } d}{\\text{total number of terms in document } d}\n",
    "$$\n",
    "\n",
    "### Exercise 1\n",
    "Complete the function `compute_tf` below.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8bd6716e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_tf(document):\n",
    "    \"\"\"\n",
    "    Computes TF for a single document (string).\n",
    "    Returns a dictionary: {term: tf_value}\n",
    "    \"\"\"\n",
    "    # Split the document into words (tokens)\n",
    "    words = # TODO\n",
    "    total_words = len(words)\n",
    "    \n",
    "    # 1. Count the frequency of each word\n",
    "    word_counts = {}\n",
    "    for word in words:\n",
    "        # TODO: Count occurrences of each word\n",
    "        # word_counts[word] = ...\n",
    "        pass \n",
    "\n",
    "    # 2. Calculate TF for each word\n",
    "    tf_dict = {}\n",
    "    \n",
    "    for word, count in word_counts.items():\n",
    "        # TODO: Calculate TF = (count of term) / (total terms)\n",
    "        # tf_dict[word] = ...\n",
    "        pass\n",
    "        \n",
    "    return tf_dict\n",
    "\n",
    "# Test with the first document\n",
    "print(\"TF for doc 0:\", compute_tf(corpus[0]))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99abf968",
   "metadata": {},
   "source": [
    "## 2. Inverse Document Frequency (IDF)\n",
    "\n",
    "**IDF** measures how important a term is. While TF considers all terms equally important, IDF weighs down frequent terms (like \"the\", \"is\") and scales up rare terms.\n",
    "\n",
    "### Formula\n",
    "$$\n",
    "IDF(t) = \\log \\left( \\frac{N}{DF(t)} \\right)\n",
    "$$\n",
    "Where:\n",
    "* $N$ = Total number of documents.\n",
    "* $DF(t)$ = Number of documents containing term $t$.\n",
    "\n",
    "*Note: Use `math.log10` or `math.log` (natural log). For this exercise, simple log is fine.*\n",
    "\n",
    "### Exercise 2\n",
    "Complete the function `compute_idf`.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4797192",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_idf(corpus):\n",
    "    \"\"\"\n",
    "    Computes IDF for the entire corpus.\n",
    "    Returns a dictionary: {term: idf_value}\n",
    "    \"\"\"\n",
    "    N = len(corpus)\n",
    "    \n",
    "    all_words_df = {}\n",
    "    \n",
    "    for doc in corpus:\n",
    "        words = # TODO: Use set to count a word only once per doc\n",
    "        \n",
    "        for word in words:\n",
    "            # TODO: Increment document frequency count for this word\n",
    "            # if word in all_words_df: ...\n",
    "            pass\n",
    "\n",
    "    idf_dict = {}\n",
    "    # 2. Calculate IDF\n",
    "    for word, df_count in all_words_df.items():\n",
    "        # TODO: Calculate IDF = log(N / df_count)\n",
    "        # idf_dict[word] = ...\n",
    "        pass\n",
    "        \n",
    "    return idf_dict\n",
    "\n",
    "# Test it\n",
    "idf_result = compute_idf(corpus)\n",
    "print(\"IDF Result:\", idf_result)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7fff49a3",
   "metadata": {},
   "source": [
    "## 3. TF-IDF\n",
    "\n",
    "Now we multiply them together:\n",
    "$$\n",
    "TF\\text{-}IDF = TF(t, d) \\times IDF(t)\n",
    "$$\n",
    "\n",
    "### Exercise 3\n",
    "Create the full TF-IDF matrix for our corpus.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d42c096",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_tfidf(corpus):\n",
    "    idf_dict = compute_idf(corpus)\n",
    "    vectors = []\n",
    "    \n",
    "    for doc in corpus:\n",
    "        tf_dict = compute_tf(doc)\n",
    "        \n",
    "        # Calculate TF-IDF for each word in the doc\n",
    "        doc_tfidf = {}\n",
    "        for word, tf_val in tf_dict.items():\n",
    "            # TODO: Multiply TF * IDF\n",
    "            # doc_tfidf[word] = ...\n",
    "            pass\n",
    "        \n",
    "        vectors.append(doc_tfidf)\n",
    "    \n",
    "    return vectors\n",
    "\n",
    "# Run the pipeline\n",
    "tfidf_vectors = compute_tfidf(corpus)\n",
    "\n",
    "# Display as a DataFrame for better visibility\n",
    "df = pd.DataFrame(tfidf_vectors)\n",
    "df = df.fillna(0) # Fill NaN with 0 (words not in document)\n",
    "print(\"My TF-IDF Matrix:\")\n",
    "print(df)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10acdda0",
   "metadata": {},
   "source": [
    "## 4. Comparison with Scikit-Learn\n",
    "Let's see how our results compare with a professional library.\n",
    "Note: Sklearn uses a slightly different IDF formula (adds 1 smoothing, different normalization), so numbers wont be identical, but should be correlated.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "663a43ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "# Setup TfidfVectorizer (defaults do normalization, we turned that off above for simplicity)\n",
    "vectorizer = TfidfVectorizer(norm=None, smooth_idf=False) # Trying to match simple logic\n",
    "\n",
    "sklearn_tfidf = vectorizer.fit_transform(corpus)\n",
    "df_sklearn = pd.DataFrame(sklearn_tfidf.toarray(), columns=vectorizer.get_feature_names_out())\n",
    "\n",
    "print(\"Sklearn TF-IDF Matrix:\")\n",
    "print(df_sklearn)\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
