{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f155d46a",
   "metadata": {},
   "source": [
    "# Programming Assignment: Building a Robust Data Pipeline\n",
    "\n",
    "Welcome to the assignment for Data Management in PyTorch.\n",
    "\n",
    "In earlier examples, you've worked with clean, pre-packaged datasets. In reality, data is rarely that simple. In computer vision, images often come in different sizes and formats and must be preprocessed before a model can learn from them. Manually handling this for thousands of images would be both tedious and error-prone.\n",
    "\n",
    "In this assignment, you’ll work with the [Plants Classification](https://www.kaggle.com/datasets/marquis03/plants-classification) dataset, which contains 30,000 `.jpg` images across 30 plant species such as aloe vera, banana, spinach, and watermelon. Like many real-world datasets, the images vary in size and quality and are organized into folders by class. For this exercise, you’ll use a subset of 3,000 images.\n",
    "\n",
    "This is where a data pipeline comes in. You’ll get hands-on experience building a custom dataset, applying the necessary transformations, and loading your data in batches. These are the essential first steps before training a deep learning model.\n",
    "\n",
    "**What You will do in this Assignment**\n",
    "\n",
    "* Access and explore the structure of an image dataset.\n",
    "* Build a custom `Dataset` class to load your images and labels on demand.\n",
    "* Define a series of `transformations`, including resizing, tensor conversion, and `normalization`, to preprocess the data.\n",
    "* Define augmentation transforms to enhance the training dataset.\n",
    "* Split the dataset into training, validation, and test sets applying the appropriate transforms to each and creating `DataLoader` instances for efficient batching.\n",
    "\n",
    "Let's get started!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18bfc0c1",
   "metadata": {},
   "source": [
    "---\n",
    "<a name='submission'></a>\n",
    "\n",
    "<h4 style=\"color:green; font-weight:bold;\">TIPS FOR SUCCESSFUL GRADING OF YOUR ASSIGNMENT:</h4>\n",
    "\n",
    "* All cells are frozen except for the ones where you need to submit your solutions or when explicitly mentioned you can interact with it.\n",
    "\n",
    "* In each exercise cell, look for comments `### START CODE HERE ###` and `### END CODE HERE ###`. These show you where to write the solution code. **Do not add or change any code that is outside these comments**.\n",
    "\n",
    "* You can add new cells to experiment but these will be omitted by the grader, so don't rely on newly created cells to host your solution code, use the provided places for this.\n",
    "\n",
    "* Avoid using global variables unless you absolutely have to. The grader tests your code in an isolated environment without running all cells from the top. As a result, global variables may be unavailable when scoring your submission. Global variables that are meant to be used will be defined in UPPERCASE.\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae41390f",
   "metadata": {},
   "source": [
    "## Table of Contents\n",
    "- [Imports](#imports)\n",
    "- [1 - Data Access](#1---data-access)\n",
    "    - [1.1 - Exploring the Dataset](#11---exploring-the-dataset)\n",
    "    - [1.2 - Creating a Custom Dataset Class](#12---creating-a-custom-dataset-class)\n",
    "        - **[Exercise 1 - PlantsDataset](#exercise-1---plantsdataset)**\n",
    "    - [1.3 - Overview of the images in the dataset](#13---overview-of-the-images-in-the-dataset)\n",
    "- [2 - Transformations](#2---transformations)\n",
    "    - [2.1 - Computing Mean and Standard Deviation](#21---computing-mean-and-standard-deviation)\n",
    "    - [2.2 - Defining Transformations](#22---defining-transformations)\n",
    "        - **[Exercise 2 - get_transformations](#exercise-2---get_transformations)**\n",
    "- [3 - Data Loading](#3---data-loading)\n",
    "    - **[Exercise 3 - get_data_loaders](#exercise-3---get_data_loaders)**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b6d6b12",
   "metadata": {},
   "source": [
    "<a name='imports'></a>\n",
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "MJUe",
   "metadata": {
    "deletable": false,
    "editable": false,
    "tags": [
     "graded"
    ]
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import torch\n",
    "from torch.utils.data import Dataset, Subset, DataLoader, random_split\n",
    "from torchvision import transforms\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "vblA",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "from tqdm.auto import tqdm\n",
    "import helper_utils\n",
    "import unittests"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "162ba742",
   "metadata": {},
   "source": [
    "<a name='1---data-access'></a>\n",
    "## 1 - Data Access "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e361e05b",
   "metadata": {},
   "source": [
    "<a name='11---exploring-the-dataset'></a>\n",
    "### 1.1 - Exploring the Dataset\n",
    "\n",
    "As you’ve already learned, the first step when working with any new dataset is to explore it. This involves understanding its structure, the types of data it contains, and identifying any potential issues such as missing values or outliers."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e431af2",
   "metadata": {},
   "source": [
    "In this step, you’ll use the `print_data_folder_structure` function from `helper_utils` to print the dataset's folder layout. \n",
    "This will help you see how the files and directories are organized, a crucial step before you start loading and preprocessing the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "PKri",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "path_dataset = './plants_dataset'\n",
    "\n",
    "helper_utils.print_data_folder_structure(path_dataset, max_depth=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ae0b539",
   "metadata": {},
   "source": [
    "You now have an initial understanding of the dataset structure:\n",
    "- `df_labels.csv`,\n",
    "- `classname.txt`,\n",
    "- One folder per class, each containing the images for that class (all in `.jpg` format).\n",
    "\n",
    "This information will be useful when you design your custom Dataset class later on."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1792269",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "# print the content of `df_labels.csv`\n",
    "df_labels = pd.read_csv(f'{path_dataset}/df_labels.csv')\n",
    "print(df_labels.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e732fa1",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "# print the content of `classname.txt`\n",
    "with open(f'{path_dataset}/classname.txt', 'r') as f:\n",
    "    class_names = f.read().splitlines()\n",
    "print(class_names)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48b48230",
   "metadata": {},
   "source": [
    "You’ve verified that `df_labels.csv` contains the labels for each image along with their corresponding file names, and that `classname.txt` contains the names of all the classes."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ddf351be",
   "metadata": {},
   "source": [
    "<a name='12---creating-a-custom-dataset-class'></a>\n",
    "### 1.2 - Creating a Custom Dataset Class\n",
    "\n",
    "It is now time to create a custom dataset class to handle the plant images dataset. \n",
    "This class will inherit from `torch.utils.data.Dataset` and will be responsible for loading and preprocessing the images along with their corresponding labels."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e20384fa",
   "metadata": {},
   "source": [
    "<a name='exercise-1---plantsdataset'></a>\n",
    "#### **Exercise 1 - `PlantsDataset`**\n",
    "\n",
    "**Your Task:**\n",
    "\n",
    "Your task is to complete the implementation of the custom PyTorch Dataset class `PlantsDataset`. \n",
    "You need to implement the missing code in multiple sections within the class:\n",
    "\n",
    "* **Complete the `__init__` method**:\n",
    "    * Load labels from the DataFrame using the already defined `load_labels` method on the `.df_info` attribute.\n",
    "    * Create a mapping from label integers to class names using the already defined `read_classname` method.\n",
    "\n",
    "* **Complete the `__len__` method**:\n",
    "    * Return the total number of samples in the dataset by extracting the length of the `.labels` attribute.\n",
    "\n",
    "* **Complete the `__getitem__` method**:\n",
    "    * Retrieve the image at the specified index using the existing `retrieve_image` method.\n",
    "    * Apply transformations to the image if they are specified.\n",
    "    * Get the corresponding label from the `.labels` attribute.\n",
    "\n",
    "<details>\n",
    "  <summary><b><font color=\"green\">Additional Code Hints (Click to expand if you are stuck)</font></b></summary>\n",
    "  \n",
    "If you need a little help, here's a more detailed guide for each method:\n",
    "\n",
    "**For the `__init__` method:**\n",
    "* For `self.labels`: Call `self.load_labels()` to extract labels from the `self.df_info` DataFrame.\n",
    "\n",
    "**For the `__len__` method:**\n",
    "* Use the built-in `len()` function on `self.labels`.\n",
    "\n",
    "**For the `__getitem__` method:**\n",
    "* Use `self.retrieve_image(idx)` to get the image at the specified index.\n",
    "* If `self.transform` is not None, apply it to the image using `self.transform(image)`.\n",
    "* Get the label from `self.labels[idx]`.\n",
    "\n",
    "</details>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8f33e29",
   "metadata": {
    "deletable": false,
    "tags": [
     "graded"
    ]
   },
   "outputs": [],
   "source": [
    "# GRADED CLASS: PlantsDataset\n",
    "class PlantsDataset(Dataset):\n",
    "    \"\"\"\n",
    "    ExDataset is a custom PyTorch Dataset for loading images and their corresponding labels from a specified directory and CSV file.\n",
    "\n",
    "    Args:\n",
    "        root_dir (str): Root directory containing the dataset files, including 'classname.txt'.\n",
    "        transform (callable, optional): Optional transform to be applied on a sample.\n",
    "\n",
    "    Attributes:\n",
    "        root_dir (str): Path to the root directory of the dataset.\n",
    "        transform (callable): Transformations to apply to the images.\n",
    "        df_info (pd.DataFrame): DataFrame containing image file names and category labels.\n",
    "        labels (list): List of integer labels for each image.\n",
    "        class_names (list): List of class names corresponding to label indices.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, root_dir, transform=None):\n",
    "        \"\"\"\n",
    "        Initializes the dataset object.\n",
    "\n",
    "        Args:\n",
    "            root_dir (str): Path to the root directory containing the dataset.\n",
    "            transform (callable, optional): Optional transform to be applied on a sample.\n",
    "        \"\"\"\n",
    "\n",
    "        # Initialize path to root directory and transformations\n",
    "        self.root_dir = root_dir\n",
    "        self.transform = transform\n",
    "\n",
    "        # Read the CSV file (with images path and category labels)\n",
    "        self.df_info = self.read_df()\n",
    "\n",
    "        ### START CODE HERE ###\n",
    "\n",
    "        # Load labels from the DataFrame using the `load_labels` method\n",
    "        self.labels = __BLANK__\n",
    "\n",
    "        # Create a mapping from label integers to class names using the `read_classname` method\n",
    "        self.class_names = __BLANK__\n",
    "\n",
    "        ### END CODE HERE ###\n",
    "\n",
    "    def read_df(self):\n",
    "        \"\"\"\n",
    "        Reads a CSV file from the specified path and returns it as a pandas DataFrame.\n",
    "        \"\"\"\n",
    "        path_csv = self.root_dir + \"/df_labels.csv\"\n",
    "        df = pd.read_csv(path_csv)\n",
    "        return df\n",
    "\n",
    "    def read_classname(self):\n",
    "        \"\"\"\n",
    "        Reads class names from a file named 'classname.txt' located in the root directory.\n",
    "\n",
    "        Returns:\n",
    "            list: A list of class names, each as a string, read from the file.\n",
    "        \"\"\"\n",
    "        path_txt = self.root_dir + \"/classname.txt\"\n",
    "        with open(path_txt, \"r\") as f:\n",
    "            class_names = f.read().splitlines()\n",
    "        return class_names\n",
    "\n",
    "    def load_labels(self, df):\n",
    "        \"\"\"\n",
    "        Extracts label integers from a DataFrame and returns them as a list.\n",
    "        \"\"\"\n",
    "        labels = []\n",
    "\n",
    "        for idx, row in df.iterrows():\n",
    "            label_int = row[\"category\"]\n",
    "            labels.append(label_int)\n",
    "        return labels\n",
    "\n",
    "    def get_label_description(self, label: int):\n",
    "        \"\"\"\n",
    "        Returns the description of a class label.\n",
    "        \"\"\"\n",
    "        description = self.class_names[label]\n",
    "        return description\n",
    "\n",
    "    def retrieve_image(self, idx: int):\n",
    "        \"\"\"\n",
    "        Retrieves and returns from the folder the PIL image at the specified index.\n",
    "        It converts the image to RGB mode.\n",
    "        \"\"\"\n",
    "        img_path = self.root_dir + \"/\" + self.df_info.iloc[idx][\"image:FILE\"]\n",
    "        with Image.open(img_path) as img:\n",
    "            image = img.convert(\"RGB\")\n",
    "        return image\n",
    "\n",
    "    ### START CODE HERE ###\n",
    "\n",
    "    def __len__(self):\n",
    "        \"\"\"\n",
    "        Returns the number of samples in the dataset.\n",
    "        \"\"\"\n",
    "        # Return the total number of samples from the `.labels` attribute\n",
    "        length = __BLANK__\n",
    "        return length\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        \"\"\"\n",
    "        Retrieves the image and its corresponding label at the specified index.\n",
    "\n",
    "        Args:\n",
    "            idx (int): Index of the item to retrieve.\n",
    "\n",
    "        Returns:\n",
    "            tuple: A tuple (image, label) where:\n",
    "                - image: The image at the given index, possibly transformed if a transform is specified.\n",
    "                - label: The label corresponding to the image.\n",
    "        \"\"\"\n",
    "        # Retrieve the image using the `retrieve_image` method\n",
    "        image = __BLANK__\n",
    "\n",
    "        # Apply the specified transformations to the image, if any\n",
    "        # The None of the if condition is not part of the exercise, leave it as is\n",
    "        if self.transform is not None:\n",
    "            image = __BLANK__\n",
    "\n",
    "        # Retrieve the label from the `labels` attribute\n",
    "        label = __BLANK__\n",
    "\n",
    "        # Return the image and label\n",
    "        return __BLANK__\n",
    "\n",
    "    ### END CODE HERE ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6c0c0d2",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "plants_dataset = PlantsDataset(root_dir=path_dataset, transform=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af228ec1",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "# print the length of the dataset\n",
    "print(f'Length of the dataset: {len(plants_dataset)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ee37f9e",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "# Look at a sample to check it's working correctly\n",
    "sel_idx = 10\n",
    "img, label = plants_dataset[sel_idx]\n",
    "\n",
    "# Visualize the image\n",
    "helper_utils.plot_img(img)\n",
    "\n",
    "# Print its description\n",
    "print(f'Description: {plants_dataset.get_label_description(label)}')\n",
    "\n",
    "# Print its shape\n",
    "print(f'Image shape: {img.size}\\n')  # PIL image size is (width, height)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "683e5645",
   "metadata": {},
   "source": [
    "##### **Expected Output**\n",
    "```\n",
    "Description: aloevera\n",
    "Image shape: (269, 187)\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92ee1f26",
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import Image\n",
    "Image('exp_out_1.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "461ee671",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "# Test your code!\n",
    "unittests.exercise_1(PlantsDataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22b167e8",
   "metadata": {},
   "source": [
    "<a name='13---overview-of-the-images-in-the-dataset'></a>\n",
    "### 1.3 - Overview of the images in the dataset\n",
    "\n",
    "The images are now accessible through the custom dataset class you implemented in the previous exercise. However, they haven’t been preprocessed yet, a necessary step before feeding them into a neural network.\n",
    "\n",
    "In this step, you’ll explore the dataset using the `visual_exploration` function from `helper_utils`.\n",
    "This function displays a few sample images along with their labels, allowing you to visually inspect the data and get a sense of its main characteristics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ROlb",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "helper_utils.visual_exploration(plants_dataset, num_rows=2, num_cols=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61dd8c15",
   "metadata": {},
   "source": [
    "From the visual exploration, you can see that the images in the dataset vary in size, color, and background.\n",
    "This kind of variability is common in real-world datasets and underscores the importance of preprocessing steps such as resizing, normalization, and data augmentation to help the model generalize effectively across different types of images."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ZHCJ",
   "metadata": {
    "marimo": {
     "config": {
      "hide_code": true
     }
    }
   },
   "source": [
    "<a name='2---transformations'></a>\n",
    "## 2 - Transformations\n",
    "\n",
    "Before feeding images into a neural network, you need to preprocess them using a series of transformations.\n",
    "These steps include resizing the images to a consistent size, converting them into tensors, and normalizing their pixel values."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66b0a120",
   "metadata": {},
   "source": [
    "<a name='21---computing-mean-and-standard-deviation'></a>\n",
    "\n",
    "### 2.1 - Computing Mean and Standard Deviation\n",
    "\n",
    "Below is an auxiliary function `get_mean_std` that computes the mean and standard deviation of the training dataset.\n",
    "These statistics are required for the normalization step in the preprocessing pipeline.\n",
    "\n",
    "Since resizing and converting images to tensors changes the pixel value distribution, the mean and standard deviation must be computed after these transformations are applied.\n",
    "\n",
    "In `get_mean_std`, you will:\n",
    "\n",
    "* **Preprocessing Setup**:\n",
    "A transform pipeline resizes images to 128×128 and converts them to tensors.\n",
    "\n",
    "* **First Pass — Compute Mean**:\n",
    "For each image, the pixels are flattened, and the channel-wise pixel values are summed globally across the entire dataset.\n",
    "Dividing by the total number of pixels yields the channel-wise mean.\n",
    "\n",
    "* **Second Pass — Compute Standard Deviation**:\n",
    "With the mean known, we compute the squared difference between each pixel and its channel mean, accumulate across the dataset, and then take the square root to obtain the channel-wise standard deviation.\n",
    "\n",
    "**Note**:\n",
    "The mean and standard deviation should usually be computed only on the training set.\n",
    "Using statistics computed from the test or validation data can introduce data leakage, where information from the evaluation set influences the training process.\n",
    "In this case, since at this point the data has not yet been split, you will compute the statistics on the entire dataset for simplicity.\n",
    "The mean and standard deviation values you obtain here will not change much when computed solely on the training set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e43ff8a",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "def get_mean_std(dataset: Dataset):\n",
    "    # Define the resizing and tensor conversion pipeline\n",
    "    preprocess = transforms.Compose(\n",
    "        [transforms.Resize((128, 128)), transforms.ToTensor()]\n",
    "    )\n",
    "    \n",
    "    # Pass 1: Mean Calculation\n",
    "    total_pixels = 0\n",
    "    sum_pixels = torch.zeros(3)\n",
    "    \n",
    "    # [Visual] Wrap dataset in tqdm to create the progress bar iterator\n",
    "    mean_loader = tqdm(dataset, desc=\"Pass 1/2: Computing Mean\")\n",
    "    \n",
    "    for img, _ in mean_loader:\n",
    "        # Core computation for mean\n",
    "        img_tensor = preprocess(img)\n",
    "        pixels = img_tensor.view(3, -1) # [channels, pixels]\n",
    "        sum_pixels += pixels.sum(dim=1)\n",
    "        total_pixels += pixels.size(1)\n",
    "    \n",
    "    mean = sum_pixels / total_pixels\n",
    "    \n",
    "    # Pass 2: Standard Deviation Calculation\n",
    "    sum_squared_diff = torch.zeros(3)\n",
    "    \n",
    "    # [Visual] Wrap dataset in tqdm to create the progress bar iterator\n",
    "    std_loader = tqdm(dataset, desc=\"Pass 2/2: Computing Std\")\n",
    "    \n",
    "    for img, _ in std_loader:\n",
    "        # Core computation for std\n",
    "        img_tensor = preprocess(img)\n",
    "        pixels = img_tensor.view(3, -1) # [channels, pixels]\n",
    "        diff = pixels - mean.unsqueeze(1)\n",
    "        sum_squared_diff += (diff ** 2).sum(dim=1)\n",
    "    \n",
    "    std = torch.sqrt(sum_squared_diff / total_pixels)\n",
    "    \n",
    "    return mean, std"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "qnkX",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "# Define the transformations to make to the images\n",
    "mean, std = get_mean_std(plants_dataset)\n",
    "\n",
    "print(f\"\\nMean: {mean}\")\n",
    "print(f\" Std: {std}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3ad828a-20fc-44b9-a6c5-8b00a75fea8b",
   "metadata": {},
   "source": [
    "<br>\n",
    "<details>\n",
    "<summary><b>The Core Algorithm (Without Progress Bar)</b></summary>\n",
    "<br>\n",
    "The function implementation above utilizes <code>tqdm</code> to provide a visual indicator of the iteration speed and estimated time remaining.\n",
    "\n",
    "It is important to understand that wrapping the dataset in `tqdm(dataset)` does not change the data or the mathematics. The iterator yields the exact same images in the exact same order. \n",
    "\n",
    "If you strip away the UI logic to focus strictly on the <b>Mathematical Algorithm</b>, the implementation looks like this:\n",
    "\n",
    "```python\n",
    "def get_mean_std(dataset: Dataset):\n",
    "    preprocess = transforms.Compose(\n",
    "        [transforms.Resize((128, 128)), transforms.ToTensor()]\n",
    "    )\n",
    "    \n",
    "    # Pass 1: Mean Calculation\n",
    "    total_pixels = 0\n",
    "    sum_pixels = torch.zeros(3)\n",
    "    \n",
    "    # Iterate directly over the dataset without the visual wrapper\n",
    "    for img, _ in dataset:\n",
    "        img_tensor = preprocess(img)\n",
    "        pixels = img_tensor.view(3, -1)  # [channels, pixels]\n",
    "        sum_pixels += pixels.sum(dim=1)\n",
    "        total_pixels += pixels.size(1)\n",
    "    \n",
    "    mean = sum_pixels / total_pixels\n",
    "    \n",
    "    # Pass 2: Standard Deviation Calculation\n",
    "    sum_squared_diff = torch.zeros(3)\n",
    "    \n",
    "    for img, _ in dataset:\n",
    "        img_tensor = preprocess(img)\n",
    "        pixels = img_tensor.view(3, -1)  # [channels, pixels]\n",
    "        diff = pixels - mean.unsqueeze(1)\n",
    "        sum_squared_diff += (diff ** 2).sum(dim=1)\n",
    "    \n",
    "    std = torch.sqrt(sum_squared_diff / total_pixels)\n",
    "    \n",
    "    return mean, std"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dac1520d",
   "metadata": {},
   "source": [
    "<a name='22---defining-transformations'></a>\n",
    "### 2.2 - Defining Transformations\n",
    "\n",
    "Having computed the mean and standard deviation of the dataset, you can now define the transformations to apply to the images.\n",
    "You’ll create two sets of transformations: one for the training set, which includes data augmentation, and another for the validation and test sets."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e292209",
   "metadata": {},
   "source": [
    "<a name='exercise-2---get_transformations'></a>\n",
    "#### **Exercise 2 - `get_transformations`**\n",
    "\n",
    "**Your Task:**\n",
    "\n",
    "Your task is to implement the missing code in the `get_transformations` function to create two image transformation pipelines for PyTorch. \n",
    "\n",
    "You will implement the following sections:\n",
    "\n",
    "* **Define `main_tfs`**:\n",
    "    * Create a `Resize` transform to resize images to 128x128 pixels.\n",
    "    * Create a `ToTensor` transform to convert PIL images to PyTorch tensors.\n",
    "    * Create a `Normalize` transform using the provided mean and standard deviation values.\n",
    "\n",
    "* **Define `augmentation_tfs`**:\n",
    "    * Create a `RandomVerticalFlip` transform with 50% probability.\n",
    "    * Create a `RandomRotation` transform that rotates images by ±15 degrees.\n",
    "\n",
    "* **Compose Transform Pipelines**:\n",
    "    * Create `main_transform` by combining the main transforms into a single pipeline using `transforms.Compose`.\n",
    "    * Create `transform_with_augmentation` by combining both augmentation and main transforms into an augmented pipeline.\n",
    "    The augmentation transforms should be applied before the main transforms.\n",
    "\n",
    "\n",
    "<details>\n",
    "  <summary><b><font color=\"green\">Additional Code Hints (Click to expand if you are stuck)</font></b></summary>\n",
    "\n",
    "If you need a little help, here's a more detailed guide for each section:\n",
    "\n",
    "**For `main_tfs`:**\n",
    "* For `Resize`: Use `transforms.Resize((128, 128))` to resize all images to 128x128 pixels.\n",
    "* For `ToTensor`: Use `transforms.ToTensor()` to convert PIL images to PyTorch tensors.\n",
    "* For `Normalize`: Use `transforms.Normalize(mean=mean, std=std)` with the provided mean and std parameters.\n",
    "\n",
    "\n",
    "**For `augmentation_tfs`:**\n",
    "* For `RandomVerticalFlip`: Use `transforms.RandomVerticalFlip(p=0.5)` to flip images vertically with 50% probability.\n",
    "* For `RandomRotation`: Use `transforms.RandomRotation(degrees=15)` to rotate images randomly within ±15 degrees.\n",
    "\n",
    "\n",
    "**For composing transforms:**\n",
    "* For `main_transform`: Use `transforms.Compose(main_tfs)` to combine the main transforms list.\n",
    "* For `transform_with_augmentation`: Use `transforms.Compose(augmentation_tfs + main_tfs)` to combine both lists.\n",
    "\n",
    "</details>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0bbbe636",
   "metadata": {
    "deletable": false,
    "editable": true,
    "tags": [
     "graded"
    ]
   },
   "outputs": [],
   "source": [
    "# GRADED FUNCTION : get_transformations\n",
    "def get_transformations(mean, std):\n",
    "    \"\"\"\n",
    "    Returns two sets of image transformation pipelines: one with basic preprocessing and another with additional data augmentation.\n",
    "\n",
    "    Args:\n",
    "        mean: Sequence of mean values for normalization.\n",
    "        std: Sequence of standard deviation values for normalization.\n",
    "\n",
    "    Returns:\n",
    "        main_transform: Transformation pipeline with resizing, tensor conversion, and normalization.\n",
    "        transform_with_augmentation: Transformation pipeline including random vertical flip, random rotation, resizing, tensor conversion, and normalization.\n",
    "    \"\"\"\n",
    "    ### START CODE HERE ###\n",
    "    main_tfs = [  \n",
    "        # Resize images to 128x128 pixels\n",
    "        __BLANK__,\n",
    "        # Convert images to PyTorch tensors\n",
    "        __BLANK__,\n",
    "        # Normalize images using the provided mean and std\n",
    "        __BLANK__\n",
    "    ]  \n",
    "\n",
    "    augmentation_tfs = [  \n",
    "        # Randomly flip the image vertically\n",
    "        __BLANK__,\n",
    "        # Randomly rotate the image by ±15 degrees\n",
    "        __BLANK__\n",
    "    ]  \n",
    "\n",
    "    # Compose the main transformations into a single pipeline\n",
    "    main_transform = __BLANK__\n",
    "\n",
    "    transform_with_augmentation = __BLANK__\n",
    "\n",
    "    ### END CODE HERE ###\n",
    "    return main_transform, transform_with_augmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "TqIu",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "# Get the transformations\n",
    "main_transform, transform_with_augmentation = get_transformations(mean, std)\n",
    "\n",
    "# Print the transformations to verify\n",
    "print(main_transform)\n",
    "print(transform_with_augmentation)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5aacc84d",
   "metadata": {},
   "source": [
    "##### **Expected Output**\n",
    "\n",
    "```\n",
    "Compose(\n",
    "    Resize(size=(128, 128), interpolation=bilinear, max_size=None, antialias=True)\n",
    "    ToTensor()\n",
    "    Normalize(mean=tensor([0.6659, 0.6203, 0.4784]), std=tensor([0.2888, 0.2884, 0.3426]))\n",
    ")\n",
    "Compose(\n",
    "    RandomVerticalFlip(p=0.5)\n",
    "    RandomRotation(degrees=[-15.0, 15.0], interpolation=nearest, expand=False, fill=0)\n",
    "    Resize(size=(128, 128), interpolation=bilinear, max_size=None, antialias=True)\n",
    "    ToTensor()\n",
    "    Normalize(mean=tensor([0.6659, 0.6203, 0.4784]), std=tensor([0.2888, 0.2884, 0.3426]))\n",
    ")\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7f3fccd",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "# Test your code!\n",
    "unittests.exercise_2(get_transformations)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36b5e749",
   "metadata": {},
   "source": [
    "You can verify your transformations by applying them to a sample image from the dataset and inspecting the result."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7585ba6a",
   "metadata": {
    "deletable": false,
    "editable": false,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Check main_transform on a sample image\n",
    "img_transformed = main_transform(img)\n",
    "print(f\"Transformed Image shape: {img_transformed.shape}\\n\")\n",
    "\n",
    "\n",
    "# get denormalization function\n",
    "denormalize = helper_utils.Denormalize(mean, std)\n",
    "# visualize the augmented image\n",
    "img_augmented = transform_with_augmentation(img)\n",
    "helper_utils.plot_img(denormalize(img_augmented), info=f\"Augmented Image\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "993bb3e2",
   "metadata": {},
   "source": [
    "<a name='3---data-loading'></a>\n",
    "## 3 - Data Loading\n",
    "\n",
    "With your custom dataset class and transformations defined, you can now create data loaders to efficiently load and batch data for training and evaluation. This is the final step before you would train a neural network on this dataset.\n",
    "\n",
    "As in the previous lab, after using `random_split` to divide the dataset into training, validation, and test sets, you need to ensure that each subset uses the appropriate transformations. \n",
    "One way to change the transformations of each subset is by wrapping the subsets in new instances of the custom dataset class `SubsetWithTransform`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f25fce01",
   "metadata": {
    "deletable": false,
    "editable": false,
    "tags": [
     "graded"
    ]
   },
   "outputs": [],
   "source": [
    "class SubsetWithTransform(Dataset):\n",
    "    \"\"\"A subset of a dataset with a specific transform applied.\"\"\"\n",
    "\n",
    "    def __init__(self, subset: Subset, transform=None):\n",
    "        # subset should be a subset WITHOUT transform\n",
    "        self.subset = subset\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.subset)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        image, label = self.subset[idx]\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "        return image, label"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c95714fa",
   "metadata": {},
   "source": [
    "<a name='exercise-3---get_data_loaders'></a>\n",
    "#### **Exercise 3 - `get_data_loaders`**\n",
    "\n",
    "**Your Task:**\n",
    "\n",
    "Your task is to complete the implementation of the `get_dataloaders` function to split a dataset and create PyTorch DataLoaders for training, validation, and testing. \n",
    "You need to implement the missing code in three main sections:\n",
    "\n",
    "* **Split the Dataset**:\n",
    "    * Use `random_split` to divide the dataset into training, validation, and test sets based on the calculated sizes.\n",
    "\n",
    "* **Apply Transforms to Each Split**:\n",
    "    * Wrap each dataset split with `SubsetWithTransform` to apply appropriate transforms.\n",
    "    * Use `augmentation_transform` for the training set to include data augmentation.\n",
    "    * Use `main_transform` for both validation and test sets (no augmentation needed).\n",
    "\n",
    "* **Create DataLoaders**:\n",
    "    * Create `DataLoader` objects for each dataset split with the specified batch size.\n",
    "    * Enable shuffling for the training loader to randomize batch order.\n",
    "    * Disable shuffling for validation and test loaders to maintain consistent evaluation.\n",
    "\n",
    "<details>\n",
    "  <summary><b><font color=\"green\">Additional Code Hints (Click to expand if you are stuck)</font></b></summary>\n",
    "  \n",
    "If you need a little help, here's a more detailed guide for each section:\n",
    "\n",
    "**For splitting the dataset:**\n",
    "* Use `random_split(dataset, [train_size, val_size, test_size])` to split the dataset.\n",
    "\n",
    "**For applying transforms:**\n",
    "* Use `SubsetWithTransform(dataset_split, transform=transform_to_apply)` for each split.\n",
    "\n",
    "**For creating DataLoaders:**\n",
    "* Use `DataLoader(dataset=dataset_split, batch_size=batch_size, shuffle=shuffle_setting)`.\n",
    "* For training loader: set `shuffle=True` to randomize the order of batches.\n",
    "* For validation and test loaders: set `shuffle=False` to maintain consistent order for evaluation.\n",
    "* All loaders should use the same `batch_size` parameter.\n",
    "\n",
    "</details>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "DnEU",
   "metadata": {
    "deletable": false,
    "editable": true,
    "tags": [
     "graded"
    ]
   },
   "outputs": [],
   "source": [
    "# GRADED FUNCTION : get_dataloaders\n",
    "def get_dataloaders(\n",
    "    dataset,\n",
    "    batch_size,\n",
    "    val_fraction,\n",
    "    test_fraction,\n",
    "    main_transform,\n",
    "    augmentation_transform,\n",
    "):\n",
    "    \"\"\"\n",
    "    Splits a dataset into training, validation, and test sets, applies specified transforms to each split,\n",
    "    and returns corresponding DataLoader objects.\n",
    "\n",
    "    Args:\n",
    "        dataset: The full dataset to be split.\n",
    "        batch_size: Number of samples per batch to load.\n",
    "        val_fraction: Fraction of the dataset to use for validation.\n",
    "        test_fraction: Fraction of the dataset to use for testing.\n",
    "        main_transform: Transform to apply to validation and test splits.\n",
    "        augmentation_transform: Transform to apply to the training split.\n",
    "\n",
    "    Returns:\n",
    "        train_loader: DataLoader for the training set with augmentation transforms.\n",
    "        val_loader: DataLoader for the validation set with main transforms.\n",
    "        test_loader: DataLoader for the test set with main transforms.\n",
    "    \"\"\"\n",
    "\n",
    "    # Calculate the sizes of each split\n",
    "    total_size = len(dataset)\n",
    "    val_size = int(total_size * val_fraction)\n",
    "    test_size = int(total_size * test_fraction)\n",
    "    train_size = total_size - val_size - test_size\n",
    "\n",
    "    ### START CODE HERE ###\n",
    "\n",
    "    # Split the dataset into training, validation, and test sets\n",
    "    train_dataset, val_dataset, test_dataset = random_split(\n",
    "            __BLANK__, __BLANK__\n",
    "    )\n",
    "\n",
    "    # Create dataset with the corresponding transforms for each split\n",
    "    train_dataset = __BLANK__\n",
    "    val_dataset = __BLANK__\n",
    "    test_dataset = __BLANK__\n",
    "\n",
    "    # Create DataLoaders for each split\n",
    "    train_loader = __BLANK__\n",
    "    val_loader = __BLANK__\n",
    "    test_loader = __BLANK__\n",
    "\n",
    "    ### END CODE HERE ###\n",
    "    return train_loader, val_loader, test_loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40c54af4",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "train_loader, val_loader, test_loader = get_dataloaders(\n",
    "    dataset=plants_dataset,\n",
    "    batch_size=32,\n",
    "    val_fraction=0.15,\n",
    "    test_fraction=0.2,\n",
    "    main_transform=main_transform,\n",
    "    augmentation_transform=transform_with_augmentation,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9632faba",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "print('=== Train Loader ===')\n",
    "print(f\"Number of batches in train_loader: {len(train_loader)}\")\n",
    "train_dataset = train_loader.dataset\n",
    "print(f\"Number of samples in train_dataset: {len(train_dataset)}\")\n",
    "print(f\"Transforms applied to train_dataset: {train_dataset.transform}\")\n",
    "print(f\"train_dataset type: {type(train_dataset)}\")\n",
    "\n",
    "print('\\n=== Test Loader ===')\n",
    "print(f\"Number of batches in test_loader: {len(test_loader)}\")\n",
    "test_dataset = test_loader.dataset\n",
    "print(f\"Number of samples in test_dataset: {len(test_dataset)}\")\n",
    "print(f\"Transforms applied to test_dataset: {test_dataset.transform}\")\n",
    "print(f\"test_dataset type: {type(test_dataset)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "685faf25",
   "metadata": {},
   "source": [
    "##### **Expected Output**\n",
    "\n",
    "```\n",
    "=== Train Loader ===\n",
    "Number of batches in train_loader: 61\n",
    "Number of samples in train_dataset: 1950\n",
    "Transforms applied to train_dataset: Compose(\n",
    "    RandomVerticalFlip(p=0.5)\n",
    "    RandomRotation(degrees=[-15.0, 15.0], interpolation=nearest, expand=False, fill=0)\n",
    "    Resize(size=(128, 128), interpolation=bilinear, max_size=None, antialias=True)\n",
    "    ToTensor()\n",
    "    Normalize(mean=tensor([0.6659, 0.6203, 0.4784]), std=tensor([0.2888, 0.2884, 0.3426]))\n",
    ")\n",
    "train_dataset type: <class '__main__.SubsetWithTransform'>\n",
    "\n",
    "=== Test Loader ===\n",
    "Number of batches in test_loader: 19\n",
    "Number of samples in test_dataset: 600\n",
    "Transforms applied to test_dataset: Compose(\n",
    "    Resize(size=(128, 128), interpolation=bilinear, max_size=None, antialias=True)\n",
    "    ToTensor()\n",
    "    Normalize(mean=tensor([0.6659, 0.6203, 0.4784]), std=tensor([0.2888, 0.2884, 0.3426]))\n",
    ")\n",
    "test_dataset type: <class '__main__.SubsetWithTransform'>\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9500e450",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "# Test your code!\n",
    "unittests.exercise_3(get_dataloaders, plants_dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae937106",
   "metadata": {
    "editable": false,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "---\n",
    "# Submission Note\n",
    "\n",
    "Congratulations! You've completed the final graded exercise of this assignment.\n",
    "\n",
    "If you've successfully passed all the unit tests above, you've completed the core requirements of this assignment. \n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "612f1953",
   "metadata": {},
   "source": [
    "## Conclusion\n",
    "\n",
    "Congratulations! You have now built an end-to-end data pipeline in PyTorch. \n",
    "\n",
    "In this lab, you learned how to construct a complete pipeline to handle a real-world image dataset. You moved beyond basic data loading to explore the core components that make up a PyTorch data pipeline.\n",
    "\n",
    "You created a custom **`Dataset`** for **data access**, defined a sequence of **transformations** such as resizing, normalization, and data augmentation to improve training robustness, split the dataset into training, validation, and test sets, and used **`DataLoader`** for efficient for efficient batching and iteration.\n",
    "\n",
    "With these fundamental components—`Dataset`, `Transforms`, and `DataLoader`—you now have a clean, efficient, and reusable workflow for preparing any image dataset for training a neural network. "
   ]
  }
 ],
 "metadata": {
  "grader_version": "1",
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
