{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "20b7ab8e",
   "metadata": {},
   "source": [
    "# Weekly Project: Image Classification with Transfer Learning\n",
    "\n",
    "In this project, you will build a complete image classification pipeline using transfer learning. You'll work with the dataset provided by your instructor.\n",
    "\n",
    "**Learning Objectives:**\n",
    "- Load and prepare image datasets for deep learning\n",
    "- Use pre-trained models for transfer learning\n",
    "- Implement two transfer learning strategies: fine-tuning and feature extraction\n",
    "- Evaluate model performance\n",
    "- Deploy models using ONNX for production (Optional)\n",
    "\n",
    "**References:**\n",
    "\n",
    "- [Training with PyTorch](https://docs.pytorch.org/tutorials/beginner/introyt/trainingyt.html)\n",
    "- [PyTorch Transfer Learning Tutorial](https://pytorch.org/tutorials/beginner/transfer_learning_tutorial.html)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f70ba841",
   "metadata": {},
   "source": [
    "## Table of Contents\n",
    "\n",
    "1. [Data Ingestion](#1)\n",
    "2. [Data Preparation](#2)\n",
    "3. [Model Building](#3)\n",
    "4. [Training](#4)\n",
    "   - [4.1 ConvNet as Fixed Feature Extractor](#4-1)\n",
    "   - [4.2 Fine-tuning the ConvNet](#4-2)\n",
    "5. [Evaluation](#5)\n",
    "6. [Inference on Custom Images](#6)\n",
    "7. [Deployment (ONNX)](#7)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "820b06f9",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7a170ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "# YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a86c3ae9",
   "metadata": {},
   "source": [
    "## Setup Device"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4057a953",
   "metadata": {},
   "source": [
    "**Note: you will need a GPU; so please run this on Colab and specify a GPU runtime (e.g., T4-GPU)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a16a3a31",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Device configuration\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f\"Using device: {device}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d7076ee",
   "metadata": {},
   "source": [
    "<a name='1'></a>\n",
    "## 1. Data Ingestion\n",
    "\n",
    "**Task**: The dataset should be downloaded and extracted to a local directory.\n",
    "\n",
    "**References:**\n",
    "\n",
    "- [Dataset and DataLoader](https://docs.pytorch.org/tutorials/beginner/introyt/trainingyt.html#dataset-and-dataloader)\n",
    "- [torchvision.datasets.ImageFolder](https://pytorch.org/vision/stable/generated/torchvision.datasets.ImageFolder.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "333a5ca9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2595f3e7",
   "metadata": {},
   "source": [
    "**Task**: create a `train_dataset` and `test_dataset` (without transforms for now)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e31cf09",
   "metadata": {},
   "outputs": [],
   "source": [
    "# YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b555b9a0",
   "metadata": {},
   "source": [
    "**Quick Check**: verify the counts of both train and test sets, match what's in the original source (Kaggle)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b85fba1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ba2e137",
   "metadata": {},
   "source": [
    "<a name='2'></a>\n",
    "## 2. Data Preparation\n",
    "\n",
    "Before training, we need to:\n",
    "1. Define augmentation for training\n",
    "2. Define normalization for both training and testing\n",
    "3. Create **`DataLoader`** for efficient batch processing\n",
    "\n",
    "**Task:** Create transformation pipelines for training and validation. Pre-trained models expect ImageNet normalization statistics.\n",
    "\n",
    "**Reference:** \n",
    "\n",
    "- [torchvision.transforms](https://pytorch.org/vision/stable/transforms.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4f5a9fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51a000f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f2353e5",
   "metadata": {},
   "source": [
    "**Quick Check**: Visualize a batch of training images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e042be0",
   "metadata": {},
   "outputs": [],
   "source": [
    "helper_utils.visualize_batch?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ea9918b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5402f6f8",
   "metadata": {},
   "source": [
    "<a name='3'></a>\n",
    "## 3. Model Building\n",
    "\n",
    "We'll use a pre-trained ResNet-18 model and adapt it for our 6-class classification task.\n",
    "\n",
    "**Task:** Load a pre-trained ResNet-18 model and modify the final layer for 6 classes.\n",
    "\n",
    "**Reference:** \n",
    "\n",
    "- [PyTorch Transfer Learning Tutorial](https://pytorch.org/tutorials/beginner/transfer_learning_tutorial.html)\n",
    "- [torchvision.models](https://pytorch.org/vision/stable/models.html)\n",
    "- [ResNet documentation](https://pytorch.org/vision/stable/models/generated/torchvision.models.resnet18.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54179b13",
   "metadata": {},
   "outputs": [],
   "source": [
    "# YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5f6e9f8",
   "metadata": {},
   "source": [
    "<a name='4'></a>\n",
    "## 4. Training\n",
    "\n",
    "**Task:** Implement a training **function** and then train using two different transfer learning strategies.\n",
    "\n",
    "**Reference:** [PyTorch Training Tutorial](https://docs.pytorch.org/tutorials/beginner/introyt/trainingyt.html#the-training-loop)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be9f00c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "167c5f55",
   "metadata": {},
   "source": [
    "<a name='4-1'></a>\n",
    "### 4.1 ConvNet as Fixed Feature Extractor\n",
    "\n",
    "In this approach, we freeze all the convolutional layers and only train the final classifier layer.\n",
    "\n",
    "**Task:** \n",
    "\n",
    "1. Load a fresh pre-trained model\n",
    "2. Freeze all parameters except the final layer\n",
    "3. Set up optimizer to only train the final layer\n",
    "4. Train the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1991e5f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df38ca2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f07a92a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a59b732",
   "metadata": {},
   "outputs": [],
   "source": [
    "# YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48895088",
   "metadata": {},
   "source": [
    "**Quick Check**: Visualize training history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41e574c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# helper_utils.visualize_training_history(history_conv)\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b7323ab",
   "metadata": {},
   "source": [
    "**Quick Check**: Visualize predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd724dd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# helper_utils.visualize_predictions(model_conv, dataloaders['val'], class_names, device, num_images=6)\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f35323cc",
   "metadata": {},
   "source": [
    "<a name='4-2'></a>\n",
    "### 4.2 Fine-tuning the ConvNet\n",
    "\n",
    "In this approach, we unfreeze all layers and train the entire network with a smaller learning rate.\n",
    "\n",
    "**Task:**\n",
    "\n",
    "1. Load a fresh pre-trained model\n",
    "2. Modify the final layer\n",
    "3. Set up optimizer for all parameters with a smaller learning rate\n",
    "4. Train the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67cc8a65",
   "metadata": {},
   "outputs": [],
   "source": [
    "# YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3390ecfd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da8aa7ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75faec80",
   "metadata": {},
   "outputs": [],
   "source": [
    "# YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3aca1a79",
   "metadata": {},
   "source": [
    "**Quick Check**: Visualize training history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "635bcbd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# helper_utils.visualize_training_history(history_ft)\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7410d1d",
   "metadata": {},
   "source": [
    "**Quick Check**: Visualize predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69ac77fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# helper_utils.visualize_predictions(model_ft, dataloaders['val'], class_names, device, num_images=6)\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c455a085",
   "metadata": {},
   "source": [
    "<a name='5'></a>\n",
    "## 5. Evaluation\n",
    "\n",
    "Compare the performance of both approaches.\n",
    "\n",
    "**Task:** Evaluate both models and compare their performance metrics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28a198cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate models on validation set\n",
    "# YOUR CODE HERE\n",
    "# Compare final validation accuracies, training times, etc.\n",
    "\n",
    "# Print comparison\n",
    "# print(\"Feature Extractor Approach:\")\n",
    "# print(f\"  Best Val Accuracy: {max(history_conv['val_acc']):.4f}\")\n",
    "# print(f\"  Final Val Accuracy: {history_conv['val_acc'][-1]:.4f}\")\n",
    "# print()\n",
    "# print(\"Fine-tuning Approach:\")\n",
    "# print(f\"  Best Val Accuracy: {max(history_ft['val_acc']):.4f}\")\n",
    "# print(f\"  Final Val Accuracy: {history_ft['val_acc'][-1]:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d44d1764",
   "metadata": {},
   "source": [
    "<a name='6'></a>\n",
    "## 6. Inference on Custom Images\n",
    "\n",
    "Test your trained model on custom images.\n",
    "\n",
    "**Task:** Load a custom image, preprocess it, and make a prediction using your trained model.\n",
    "\n",
    "**Reference:** [Image Preprocessing](https://pytorch.org/vision/stable/transforms.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ddf5b0f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make prediction on a custom image\n",
    "# img_path = 'path/to/your/image.jpg'\n",
    "\n",
    "# YOUR CODE HERE\n",
    "# Use helper_utils.visualize_single_prediction or helper_utils.predict_single_image\n",
    "# helper_utils.visualize_single_prediction(\n",
    "#     model_ft,  # or model_conv\n",
    "#     img_path,\n",
    "#     data_transforms['val'],\n",
    "#     class_names,\n",
    "#     device\n",
    "# )\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1cb4ced4",
   "metadata": {},
   "source": [
    "# üèÜüéâ Congratulations on completing the Weekly Final Project! üéâüèÜ\n",
    "\n",
    "Fantastic job on finishing the Weekly Final Project! You‚Äôve put your skills to the test and made it to the end. Take a moment to celebrate your hard work and dedication. Keep up the great work and continue your learning journey!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0919579",
   "metadata": {},
   "source": [
    "<a name='7'></a>\n",
    "## 7. Deployment (ONNX)\n",
    "\n",
    "Convert your trained model to ONNX format for deployment.\n",
    "\n",
    "**Task:** \n",
    "1. Convert the PyTorch model to ONNX format\n",
    "2. Load the ONNX model and perform inference\n",
    "\n",
    "**Reference:** \n",
    "- [PyTorch to ONNX](https://docs.pytorch.org/tutorials/beginner/onnx/export_simple_model_to_onnx_tutorial.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2573ceee",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert model to ONNX\n",
    "# YOUR CODE HERE\n",
    "\n",
    "# Set model to evaluation mode\n",
    "# model_ft.eval()\n",
    "\n",
    "# Create dummy input (batch_size=1, channels=3, height=224, width=224)\n",
    "# dummy_input = torch.randn(1, 3, 224, 224).to(device)\n",
    "\n",
    "# Export to ONNX\n",
    "# onnx_path = 'model.onnx'\n",
    "# torch.onnx.export(\n",
    "#     model_ft,\n",
    "#     dummy_input,\n",
    "#     onnx_path,\n",
    "#     input_names=['input'],\n",
    "#     output_names=['output'],\n",
    "#     dynamic_axes={'input': {0: 'batch_size'}, 'output': {0: 'batch_size'}}\n",
    "# )\n",
    "\n",
    "# print(f\"Model exported to {onnx_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fed08bba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load ONNX model and perform inference\n",
    "# YOUR CODE HERE\n",
    "\n",
    "# Load ONNX model\n",
    "# ort_session = ort.InferenceSession(onnx_path)\n",
    "\n",
    "# Prepare input (use validation transform)\n",
    "# img_path = 'path/to/test/image.jpg'\n",
    "# img = Image.open(img_path).convert('RGB')\n",
    "# img_tensor = data_transforms['val'](img).unsqueeze(0)\n",
    "# img_numpy = img_tensor.numpy()\n",
    "\n",
    "# Run inference\n",
    "# outputs = ort_session.run(None, {'input': img_numpy})\n",
    "# predictions = np.array(outputs[0])\n",
    "# pred_class_idx = np.argmax(predictions[0])\n",
    "# pred_class = class_names[pred_class_idx]\n",
    "# confidence = np.max(predictions[0])\n",
    "\n",
    "# print(f\"Predicted: {pred_class} (confidence: {confidence:.2%})\")"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
