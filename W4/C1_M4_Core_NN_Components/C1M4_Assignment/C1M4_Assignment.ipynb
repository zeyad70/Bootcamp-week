{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8b21cfc0-db1b-4afd-b3a7-368cdc6daeb4",
   "metadata": {},
   "source": [
    "# Programming Assignment - Overcoming Overfitting: Building a Robust CNN\n",
    "\n",
    "Welcome to the final assignment of this course! You have built a solid foundation in PyTorch, moving from basic tensors to a complete, working Convolutional Neural Network in a previous lab. That was an essential first step. Now, it is time to take the next step and tackle a challenge that every deep learning practitioner faces: to take a promising but flawed model and elevate it. \n",
    "\n",
    "Your previous model showed clear signs of overfitting, a common hurdle where a network memorizes training data instead of learning to generalize. This assignment is your mission to solve that problem, not just by tweaking a parameter, but by systematically re-engineering your entire machine learning pipeline with a suite of professional tools and techniques.\n",
    "\n",
    "To accomplish this, you will deploy a multi-faceted strategy, upgrading every component of your setup:\n",
    "\n",
    "* **Enhance the Data Pipeline** with more powerful data augmentation to create a richer training set.\n",
    "\n",
    "* **Refactor the Architecture for Modularity**, creating reusable `CNNBlocks` for cleaner, more scalable code.\n",
    "\n",
    "* **Integrate Advanced Layers** like **Batch Normalization** to stabilize training and improve generalization.\n",
    "\n",
    "* **Deploy a Robust Regularization Strategy** using **Dropout** and **Weight Decay** to combat overfitting directly.\n",
    "\n",
    "Let's get started and elevate your model to the next level!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d7b4bb9-517f-4991-9d5e-962722e36105",
   "metadata": {},
   "source": [
    "---\n",
    "<a name='submission'></a>\n",
    "\n",
    "<h4 style=\"color:green; font-weight:bold;\">TIPS FOR SUCCESSFUL GRADING OF YOUR ASSIGNMENT:</h4>\n",
    "\n",
    "* All cells are frozen except for the ones where you need to submit your solutions or when explicitly mentioned you can interact with it.\n",
    "\n",
    "* In each exercise cell, look for comments `### START CODE HERE ###` and `### END CODE HERE ###`. These show you where to write the solution code. **Do not add or change any code that is outside these comments**.\n",
    "\n",
    "* You can add new cells to experiment but these will be omitted by the grader, so don't rely on newly created cells to host your solution code, use the provided places for this.\n",
    "\n",
    "* Avoid using global variables unless you absolutely have to. The grader tests your code in an isolated environment without running all cells from the top. As a result, global variables may be unavailable when scoring your submission. Global variables that are meant to be used will be defined in UPPERCASE.\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06328542-e3ff-43b1-be7f-1cef351ba6ff",
   "metadata": {},
   "source": [
    "## Table of Contents\n",
    "- [Imports](#0)\n",
    "- [1 - Upgrading Your Data Pipeline](#1)\n",
    "    - [1.1 - Defining More Powerful Transformations](#1-1)\n",
    "        - **[Exercise 1 - define_transformations](#ex-1)**\n",
    "    - [1.2 - Assembling the Data Loaders](#1-2)\n",
    "    - [1.3 - Visualizing the Training Images](#1-3)\n",
    "- [2 - Building a Modular and Robust CNN](#2)\n",
    "    - [2.1 - The Power of Modularity: The CNNBlock](#2-1)\n",
    "        - [2.1.1 - BatchNorm2d Layer](#2-1-1)\n",
    "            - **[Exercise 2 - CNNBlock](#ex-2)**\n",
    "    - [2.2 - Assembling the Full CNN with Modular Blocks](#2-2)\n",
    "        - **[Exercise 3 - SimpleCNN](#ex-3)**\n",
    "- [3 - Training the Upgraded Model](#3)\n",
    "    - [3.1 - Configuring the Loss and Optimizer](#3-1)\n",
    "    - [3.2 - Implementing the Training and Validation Logic](#3-2)    \n",
    "        - **[Exercise 4 - train_epoch](#ex-4)**\n",
    "        - **[Exercise 5 - validate_epoch](#ex-5)**        \n",
    "- [4 - Beyond the Foundations: A Glimpse into the Next Level](#4)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f583f9a-3bc9-4ef1-b846-6803314e4dd1",
   "metadata": {},
   "source": [
    "<a name='0'></a>\n",
    "\n",
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a33a321-ef93-4897-8b99-36f771c1ccb2",
   "metadata": {
    "deletable": false,
    "editable": false,
    "tags": [
     "graded"
    ]
   },
   "outputs": [],
   "source": [
    "import copy \n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torchvision.transforms as transforms\n",
    "from torch.utils.data import DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3762cc3c-c631-4ad4-a0dc-2ea2d88d471a",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "import helper_utils\n",
    "import unittests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06f1e750-6b47-4ce2-be85-b518be0e99d5",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "# Device configuration\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f\"Using device: {device}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03b66c5c-c3ae-40c2-a170-1c0e007e5876",
   "metadata": {},
   "source": [
    "<a name='1'></a>\n",
    "## 1 - Upgrading Your Data Pipeline\n",
    "\n",
    "In the first lab of this module, you built a powerful CNN classifier from scratch. While it worked, you also encountered a classic machine learning hurdle: **overfitting**. Your model started to memorize the training data instead of learning to generalize, a common issue when a model's performance on validation data stalls or degrades.\n",
    "\n",
    "Your training results from that lab likely produced a plot similar to the one below. It perfectly illustrates this challenge, showing the telltale signs of overfitting. Look closely at the widening gap between the **training loss**, which continues to improve, and the **validation loss**, which stagnates or even worsens. This divergence, along with the **validation accuracy** hitting a plateau, is the classic evidence of a model that is memorizing the training data instead of truly learning how to generalize.\n",
    "\n",
    "A fundamental strategy for building more robust models is **data augmentation**. By creating modified versions of your training images, flipping them, rotating them, you teach your model to recognize subjects in a variety of conditions. This technique is a pivotal first line of defense against overfitting. Your first task is to build an even more powerful set of image transformations to supercharge your dataset.\n",
    "\n",
    "<a name='1-1'></a>\n",
    "### 1.1 - Defining More Powerful Transformations\n",
    "\n",
    "Let's begin by setting up the essential components for your data pipeline. You will start by defining the standard normalization values for the CIFAR-100 dataset and then create the transformation pipelines themselves.\n",
    "\n",
    "* Define the `cifar100_mean` and `cifar100_std`, the mean and standard deviation values for the **CIFAR-100** dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76db4ecd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import Image\n",
    "Image('./nb_image/lab_1_training_plot.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e5785e2-916d-4fbf-b753-85416867acaa",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "# Pre-calculated mean for each of the 3 channels of the CIFAR-100 dataset\n",
    "cifar100_mean = (0.5071, 0.4867, 0.4408)\n",
    "# Pre-calculated standard deviation for each of the 3 channels of the CIFAR-100 dataset\n",
    "cifar100_std = (0.2675, 0.2565, 0.2761)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30f42d86-745f-4b98-a835-0f3311505ab3",
   "metadata": {},
   "source": [
    "As you learned previously, the training transformation pipeline is where you apply data augmentation. To make your model even more robust, you will add a new technique to your arsenal this time: `RandomVerticalFlip`. While horizontal flipping is common, adding vertical flips can also help the model learn that an object's orientation might not always be upright, a useful feature for classifying things like insects or flowers from various angles.\n",
    "\n",
    "<a name='ex-1'></a>\n",
    "### Exercise 1 - define_transformations\n",
    "\n",
    "Your task is to define two distinct image transformation pipelines using `torchvision.transforms`.\n",
    "\n",
    "**Your Task**:\n",
    "\n",
    "* **For `train_transformations`**: Create a composition of transforms for the training dataset.\n",
    ">\n",
    "    * This pipeline should include random [horizontal](https://docs.pytorch.org/vision/main/generated/torchvision.transforms.RandomHorizontalFlip.html) and [vertical](https://docs.pytorch.org/vision/main/generated/torchvision.transforms.RandomVerticalFlip.html) flips.\n",
    "    * It should also randomly [rotate](https://docs.pytorch.org/vision/main/generated/torchvision.transforms.RandomRotation.html) the images by up to **15 degrees**.\n",
    "    * Finally, it must convert images to PyTorch [tensors](https://docs.pytorch.org/vision/main/generated/torchvision.transforms.ToTensor.html) and [normalize](https://docs.pytorch.org/vision/main/generated/torchvision.transforms.Normalize.html) them using the provided `mean` and `std`.\n",
    ">\n",
    "* **For `val_transformations`**: Create a second, simpler pipeline for the validation dataset.\n",
    ">\n",
    "    * This pipeline should only perform the two essential steps: converting images to [tensors](https://docs.pytorch.org/vision/main/generated/torchvision.transforms.ToTensor.html) and [normalizing](https://docs.pytorch.org/vision/main/generated/torchvision.transforms.Normalize.html) them with the same `mean` and `std`.\n",
    "\n",
    "<details>\n",
    "<summary><b><font color=\"green\">Additional Code Hints (Click to expand if you are stuck)</font></b></summary>\n",
    "\n",
    "If you're stuck, here is a more detailed breakdown.\n",
    "\n",
    "You will use `transforms.Compose([...])` to create a list of transformations for both pipelines. All the required functions are part of the `transforms` module.\n",
    "\n",
    "**For `train_transformations`**:\n",
    "\n",
    "* You need to create a list of five transformation objects inside `transforms.Compose`.\n",
    "\n",
    "* The first one is for horizontal flips. The call looks like this: `transforms.RandomHorizontalFlip()`.\n",
    "\n",
    "* The next two for vertical flips and rotations follow a similar pattern. Remember to pass `15` as the argument for the rotation.\n",
    "\n",
    "* The last two transformations are:\n",
    "\n",
    "    * `call the ToTensor method from the transforms module`\n",
    "\n",
    "    * `call the Normalize method from the transforms module, passing it the mean and std variables`\n",
    "\n",
    "**For `val_transformations`**:\n",
    "\n",
    "* This pipeline is much simpler and only contains the last two steps from the training pipeline.\n",
    "\n",
    "* Your list inside `transforms.Compose` should contain just two items:\n",
    "\n",
    "    * `first, the transformation to convert an image to a tensor`\n",
    "\n",
    "    * `second, the transformation to normalize the tensor using the given mean and std`\n",
    "\n",
    "</details>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48268d0f-492c-4de7-9e4a-8b7c83b070ff",
   "metadata": {
    "deletable": false,
    "tags": [
     "graded"
    ]
   },
   "outputs": [],
   "source": [
    "# GRADED FUNCTION: define_transformations\n",
    "\n",
    "def define_transformations(mean, std):\n",
    "    \"\"\"\n",
    "    Creates image transformation pipelines for training and validation.\n",
    "\n",
    "    Args:\n",
    "        mean (list or tuple): A sequence of mean values for each channel.\n",
    "        std (list or tuple): A sequence of standard deviation values for each channel.\n",
    "\n",
    "    Returns:\n",
    "        train_transformations (torchvision.transforms.Compose): The training\n",
    "                                                                transformation pipeline.\n",
    "        val_transformations (torchvision.transforms.Compose): The validation\n",
    "                                                                transformation pipeline.\n",
    "    \"\"\"\n",
    "    \n",
    "    ### START CODE HERE ###\n",
    "    \n",
    "    # Define the sequence of transformations for the training dataset.\n",
    "    \n",
    "    train_transformations = __BLANK__([\n",
    "        # Randomly flip the image horizontally with a 50% probability.\n",
    "        __BLANK__,\n",
    "        # Randomly flip the image vertically with a 50% probability.\n",
    "        __BLANK__,\n",
    "        # Rotate the image by a random angle between -15 and +15 degrees.\n",
    "        __BLANK__,\n",
    "        # Convert the image from a PIL Image or NumPy array to a PyTorch tensor.\n",
    "        __BLANK__,\n",
    "        # Normalize the tensor image with the given mean and standard deviation.\n",
    "        __BLANK__\n",
    "    ]) \n",
    "    \n",
    "    # Define the sequence of transformations for the validation dataset.\n",
    "    val_transformations = __BLANK__([\n",
    "        # Convert the image from a PIL Image or NumPy array to a PyTorch tensor.\n",
    "        __BLANK__,\n",
    "        # Normalize the tensor image with the given mean and standard deviation.\n",
    "        __BLANK__\n",
    "    ]) \n",
    "    \n",
    "    ### END CODE HERE ###\n",
    "\n",
    "    # Return both transformation pipelines.\n",
    "    return train_transformations, val_transformations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d76e0001-3d4a-400f-aab4-2fccbc3f8d2f",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "# Verify the Transformations\n",
    "print(\"--- Verifying define_transformations ---\\n\")\n",
    "train_transform_verify, val_transform_verify = define_transformations(cifar100_mean, cifar100_std)\n",
    "\n",
    "\n",
    "print(\"Training Transformations:\")\n",
    "print(train_transform_verify)\n",
    "print(\"-\" * 30)\n",
    "print(\"\\nValidation Transformations:\")\n",
    "print(val_transform_verify)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d77c564-95c0-4a74-8cdb-6775049c51b0",
   "metadata": {},
   "source": [
    "#### Expected Output:\n",
    "\n",
    "```\n",
    "Training Transformations:\n",
    "Compose(\n",
    "    RandomHorizontalFlip(p=0.5)\n",
    "    RandomVerticalFlip(p=0.5)\n",
    "    RandomRotation(degrees=[-15.0, 15.0], interpolation=nearest, expand=False, fill=0)\n",
    "    ToTensor()\n",
    "    Normalize(mean=(0.5071, 0.4867, 0.4408), std=(0.2675, 0.2565, 0.2761))\n",
    ")\n",
    "------------------------------\n",
    "\n",
    "Validation Transformations:\n",
    "Compose(\n",
    "    ToTensor()\n",
    "    Normalize(mean=(0.5071, 0.4867, 0.4408), std=(0.2675, 0.2565, 0.2761))\n",
    ")\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0e9bcb7-841d-4819-90eb-5107c8cb30f7",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "# Test your code!\n",
    "unittests.exercise_1(define_transformations)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f21aa4a5-53aa-4bd1-a6b0-e0b77b7cd482",
   "metadata": {},
   "source": [
    "* Call the `define_transformations` function, passing the `cifar100_mean` and `cifar100_std` as arguments.\n",
    "* This returns two separate transformation pipelines, which are stored in the `train_transform` and `val_transform` variables for later use."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d748fc54-639e-48a0-ad17-eb7b8636224a",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "# Create and store the training and validation transformation pipelines\n",
    "train_transform, val_transform = define_transformations(cifar100_mean, cifar100_std)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d82a97e-14c7-4972-bf90-e1d689c7cf5e",
   "metadata": {},
   "source": [
    "<a name='1-2'></a>\n",
    "### 1.2 - Assembling the Data Loaders\n",
    "\n",
    "With your powerful new transformation pipelines defined, it is time to prepare the data for training. You will first specify the 15 target classes and then use your transformations to load the images and wrap them in `DataLoader` objects, which will feed the data to your model in batches.\n",
    "\n",
    "* First, define the `all_target_classes` list.\n",
    "* These are the same classes of flowers, mammals, and insects you worked with in the previous lab, ensuring you are tackling the same classification problem, but with an upgraded pipeline."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e69421f3-9f65-4fb3-8369-19b01b25f3b7",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "# Define the full class list.\n",
    "all_target_classes = [\n",
    "    # Flowers\n",
    "    'orchid', 'poppy', 'rose', 'sunflower', 'tulip',\n",
    "    # Mammals\n",
    "    'fox', 'porcupine', 'possum', 'raccoon', 'skunk',\n",
    "    # Insects\n",
    "    'bee', 'beetle', 'butterfly', 'caterpillar', 'cockroach'\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7bcf919e-cee5-4365-805c-6c1aa3757f67",
   "metadata": {},
   "source": [
    "* Next, call the `load_cifar100_subset` function, passing in your class list (`all_target_classes`) and both transformation pipelines (`train_transform` and `val_transform`).\n",
    "* This function handles the entire loading process and returns two PyTorch `Dataset` objects, which are stored in the `train_dataset` and `val_dataset` variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42d805d7-c101-4fa7-82c0-3baa99415f39",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "# Load the full datasets.\n",
    "train_dataset, val_dataset = helper_utils.load_cifar100_subset(all_target_classes, train_transform, val_transform)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b76e20de-b8e9-4dda-b1d8-f20919a48fc4",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "With your datasets prepared, the final step is to wrap them in PyTorch's `DataLoader`. This utility is essential for feeding data to your model in manageable batches.\n",
    "\n",
    "* Create the `train_loader` for your training data.\n",
    "* Create the `val_loader` for your validation data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7cb0bbe4-86ea-497c-8de3-e60628571a92",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "# Set the number of samples to be processed in each batch\n",
    "batch_size = 64\n",
    "\n",
    "# Create a data loader for the training set, with shuffling enabled\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "# Create a data loader for the validation set, without shuffling\n",
    "val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11b5a76f-f818-4ec5-8346-4e1ed788c469",
   "metadata": {},
   "source": [
    "<a name='1-3'></a>\n",
    "### 1.3 - Visualizing the Training Images\n",
    "\n",
    "It is always a good practice to visualize your data. The following line calls a helper function to display a grid of random images from your `train_loader`.\n",
    "\n",
    "Pay close attention to the output. Since these images come from the training set, you should see the effects of your data augmentation pipeline in action. Look for images that have been randomly flipped horizontally, vertically, or rotated. This is an excellent way to confirm your transformations are working as expected."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fafe015-9d6c-4e4d-ba82-5879d9ff6c27",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "# Visualize a grid of random training images\n",
    "helper_utils.visualise_images(train_loader, grid=(3, 5))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10fcb73f-bc90-43d1-acda-79022cd0645d",
   "metadata": {},
   "source": [
    "<a name='2'></a>\n",
    "## 2 - Building a Modular and Robust CNN\n",
    "\n",
    "With a more robust data pipeline in place, your next step is to enhance the model's architecture itself. You will refactor the original CNN to be more modular, efficient, and powerful. This is the next pivotal step toward resolving the overfitting problem and pushing your model's performance to new heights.\n",
    "\n",
    "<a name='2-1'></a>\n",
    "### 2.1 - The Power of Modularity: The CNNBlock\n",
    "\n",
    "In the previous lab, your model's architecture had a repeating pattern of convolution, activation, and pooling layers. Defining these layers individually can become repetitive and makes the model harder to modify. A much better approach is to group these patterns into a single, reusable module. Your first task is to create a `CNNBlock` that packages these layers together. This modular design makes your main model's code significantly cleaner and easier to manage.\n",
    "\n",
    "<a name='2-1-1'></a>\n",
    "#### 2.1.1 - <code>[BatchNorm2d Layer](https://docs.pytorch.org/docs/stable/generated/torch.nn.BatchNorm2d.html)</code>\n",
    "\n",
    "As part of this new, improved block, you will also introduce a powerful new layer: `BatchNorm2d`. This layer is a pivotal technique for building modern, high performing deep neural networks.\n",
    "\n",
    "Think of Batch Normalization as a traffic controller for the data flowing between your network's layers. After a convolutional layer processes a batch of images, the outputs (or activations) can have widely varying distributions from one batch to the next. `BatchNorm2d` steps in and normalizes these activations within each mini batch, adjusting them to have a consistent mean and standard deviation. It then uses two learnable parameters to scale and shift this normalized output, allowing the network itself to learn the optimal distribution for the data at that point.\n",
    "\n",
    "This seemingly simple step provides three profound benefits:\n",
    "\n",
    "* **It Stabilizes and Accelerates Training**: By keeping the distribution of data consistent between layers, it prevents later layers from having to constantly adapt to a shifting input from the layers before them. This stability allows you to use higher learning rates, which can dramatically speed up how quickly your model learns.\n",
    "\n",
    "* **It Acts as a Regularizer**: Because the normalization statistics are calculated for each unique mini batch, it introduces a slight amount of noise into the training process. This noise makes it harder for the model to perfectly memorize the training data, encouraging it to learn more general features and thus reducing overfitting.\n",
    "\n",
    "* **It Reduces Sensitivity to Initialization**: The layer makes your model less dependent on the specific random weights it starts with, leading to more reliable and repeatable training results.\n",
    "\n",
    "By adding `BatchNorm2d` to your `CNNBlock`, you are not just adding another layer; you are fundamentally making your model's training process more stable, efficient, and robust.\n",
    "\n",
    "<a name='ex-2'></a>\n",
    "### Exercise 2 - CNNBlock\n",
    "\n",
    "You will now implement the `CNNBlock` class. This class will package the four layers into a single `nn.Sequential` module.\n",
    "\n",
    "**Your Task**:\n",
    "\n",
    "**Inside the `__init__` method**:\n",
    "> * You need to define a sequential container named `self.block`.\n",
    "> * Inside this <code>[nn.Sequential](https://docs.pytorch.org/docs/stable/generated/torch.nn.Sequential.html)</code> container, you will add the following layers in order:\n",
    ">    1. A <code>[nn.Conv2d](https://docs.pytorch.org/docs/stable/generated/torch.nn.Conv2d.html)</code> layer. Use the `in_channels`, `out_channels`, `kernel_size`, and `padding` arguments that are passed to the `__init__` method.\n",
    ">    2. A <code>[nn.BatchNorm2d](https://docs.pytorch.org/docs/stable/generated/torch.nn.BatchNorm2d.html)</code> layer. This layer needs to know the number of channels of its input, which is the output of the previous convolutional layer.\n",
    ">    3. A <code>[nn.ReLU](https://docs.pytorch.org/docs/stable/generated/torch.nn.ReLU.html)</code> activation function.\n",
    ">    4. A <code>[nn.MaxPool2d](https://docs.pytorch.org/docs/stable/generated/torch.nn.MaxPool2d.html)</code> layer. This will downsample the feature map. You should set both the `kernel_size` and `stride` to `2`.\n",
    "\n",
    "**Inside the `forward` method**:\n",
    "\n",
    "> * This method performs the forward pass.\n",
    "> * Pass the input tensor `x` through the `self.block` you defined and return the result.\n",
    "\n",
    "<details>\n",
    "<summary><b><font color=\"green\">Additional Code Hints (Click to expand if you are stuck)</font></b></summary>\n",
    "\n",
    "If you are looking for more guidance, here is a detailed breakdown.\n",
    "\n",
    "**For the `__init__` method**:\n",
    "\n",
    "* You are defining a sequence of layers. The entire sequence will be assigned to `self.block`. The structure starts like this: `self.block = nn.Sequential(...)`.\n",
    "\n",
    "* The layers are provided as arguments to `nn.Sequential`, separated by commas.\n",
    "\n",
    "* **1. Convolutional Layer**: The first layer is `nn.Conv2d(in_channels, out_channels, kernel_size=kernel_size, padding=padding)`. Notice how it uses the parameters from the `__init__` method's signature.\n",
    "\n",
    "* **2. Batch Norm Layer**: The second layer is `nn.BatchNorm2d(...)`. It needs one argument: the number of channels it will normalize. This is equal to the number of output channels from the previous layer, which is `out_channels`.\n",
    "\n",
    "* **3. ReLU Layer**: The third layer is simply `nn.ReLU()`. It does not require any arguments.\n",
    "\n",
    "* **4. Max Pooling Layer**: The final layer is `nn.MaxPool2d(...)`. You need to provide the `kernel_size` and `stride`. The call will look like: `nn.MaxPool2d(kernel_size=2, stride=2)`.\n",
    "\n",
    "**For the `forward` method**:\n",
    "\n",
    "* This is a single line of code. You simply need to call the module you created in the `__init__` method on the input tensor.\n",
    "* The pseudocode would be: `return the result of applying self.block to the input x`.\n",
    "\n",
    "</details>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cea01e0f-9910-4de3-a431-7dcaac779817",
   "metadata": {
    "deletable": false,
    "tags": [
     "graded"
    ]
   },
   "outputs": [],
   "source": [
    "# GRADED CLASS: CNNBlock\n",
    "\n",
    "class CNNBlock(nn.Module):\n",
    "    \"\"\"\n",
    "    Defines a single convolutional block for a CNN.\n",
    "\n",
    "    This block consists of a convolutional layer, batch normalization,\n",
    "    a ReLU activation, and a max-pooling layer, bundled as a sequential module.\n",
    "    \"\"\"\n",
    "    def __init__(self, in_channels, out_channels, kernel_size=3, padding=1):\n",
    "        \"\"\"\n",
    "        Initializes the layers of the CNNBlock.\n",
    "\n",
    "        Args:\n",
    "            in_channels (int): Number of channels in the input image.\n",
    "            out_channels (int): Number of channels produced by the convolution.\n",
    "            kernel_size (int, optional): Size of the convolving kernel. Defaults to 3.\n",
    "            padding (int, optional): Zero-padding added to both sides of the input. Defaults to 1.\n",
    "        \"\"\"\n",
    "        # Initialize the parent nn.Module class.\n",
    "        super(CNNBlock, self).__init__()\n",
    "        \n",
    "        ### START CODE HERE ###\n",
    "        \n",
    "        # Define the sequential container for the block's layers.\n",
    "        self.block = __BLANK__(\n",
    "            # 2D convolutional layer to apply learnable filters to the input.\n",
    "            __BLANK__,\n",
    "            # Batch normalization to stabilize and accelerate training.\n",
    "            __BLANK__,\n",
    "            # ReLU activation function to introduce non-linearity.\n",
    "            __BLANK__,\n",
    "            # Max pooling layer to downsample the feature map and reduce spatial dimensions.\n",
    "            __BLANK__\n",
    "        ) \n",
    "        \n",
    "        ### END CODE HERE ###\n",
    "\n",
    "    def forward(self, x):\n",
    "        \"\"\"\n",
    "        Defines the forward pass for the CNNBlock.\n",
    "\n",
    "        Args:\n",
    "            x: The input tensor for the block.\n",
    "\n",
    "        Returns:\n",
    "            The output tensor after passing through the block.\n",
    "        \"\"\"\n",
    "        \n",
    "        ### START CODE HERE ###\n",
    "        \n",
    "        # Pass the input tensor through the sequential block of layers.\n",
    "        x = __BLANK__\n",
    "        return x\n",
    "    \n",
    "        ### END CODE HERE ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87f3fe7b-7ec3-47fc-bbac-24d8b3090a9c",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "# Verify the CNNBlock\n",
    "print(\"--- Verifying CNNBlock ---\\n\")\n",
    "\n",
    "# Instantiate the block with 3 input channels and 16 output channels\n",
    "verify_cnn_block = CNNBlock(in_channels=3, out_channels=16)\n",
    "print(\"Block Structure:\\n\")\n",
    "print(verify_cnn_block)\n",
    "\n",
    "# Verify the output shape after a forward pass\n",
    "# Create a dummy input tensor (batch_size=1, channels=3, height=32, width=32)\n",
    "dummy_input = torch.randn(1, 3, 32, 32)\n",
    "print(f\"\\nInput tensor shape:  {dummy_input.shape}\")\n",
    "\n",
    "# Pass the dummy tensor through the block\n",
    "output = verify_cnn_block(dummy_input)\n",
    "print(f\"Output tensor shape: {output.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5cd9cccb-9757-4c7f-a694-69c34d72cf9b",
   "metadata": {},
   "source": [
    "#### Expected Output:\n",
    "\n",
    "```\n",
    "Block Structure:\n",
    "\n",
    "CNNBlock(\n",
    "  (block): Sequential(\n",
    "    (0): Conv2d(3, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
    "    (1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
    "    (2): ReLU()\n",
    "    (3): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
    "  )\n",
    ")\n",
    "\n",
    "Input tensor shape:  torch.Size([1, 3, 32, 32])\n",
    "Output tensor shape: torch.Size([1, 16, 16, 16])\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8db20525-3776-4cd3-a503-62675dfc6270",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "# Test your code!\n",
    "unittests.exercise_2(CNNBlock)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75875497-665f-45cd-b237-ac8f54962ded",
   "metadata": {},
   "source": [
    "<a name='2-2'></a>\n",
    "### 2.2 - Assembling the Full CNN with Modular Blocks\n",
    "Now that you have a reusable `CNNBlock`, you can assemble your full `SimpleCNN` architecture. By using your new modular block, you will see how much cleaner and more professional your model definition becomes. Instead of defining many individual layers for the convolutional part of your network, you will now define just three `CNNBlock` instances.\n",
    "\n",
    "Your model will consist of two main parts:\n",
    "\n",
    "* **A feature extractor**: A sequence of three CNNBlocks that will learn to identify visual patterns in the images.\n",
    "* **A classifier**: A sequence of fully connected layers that will take the features from the convolutional blocks and make the final prediction.\n",
    "\n",
    "In this new version, you will also increase the **dropout rate to `0.6`**. This is another important step in your fight against overfitting, as it makes the model less likely to rely on any single feature.\n",
    "\n",
    "<a name='ex-3'></a>\n",
    "### Exercise 3 - SimpleCNN\n",
    "\n",
    "You will now implement the `__init__` and `forward` methods for the `SimpleCNN` class. You will use the `CNNBlock` you just built as the primary component of the network's body.\n",
    "\n",
    "**Your Task**:\n",
    "\n",
    "**Inside the `__init__` method**:\n",
    "\n",
    "> * **Feature Extractor**:\n",
    ">\n",
    ">    * Instantiate three `CNNBlock` layers (`conv_block1`, `conv_block2`, `conv_block3`).\n",
    ">    * The first block should take an input with **3 channels** (for RGB images) and produce **32 output channels**.\n",
    ">    * For the subsequent blocks, the number of input channels must match the number of output channels from the previous block. You will double the number of channels at each step `(3 -> 32 -> 64 -> 128)`.\n",
    "\n",
    "> * **Classifier**:\n",
    ">\n",
    ">    * Define a `self.classifier` using an `nn.Sequential` container.\n",
    ">    * This container should have the following layers in order:\n",
    ">        1. An <code>[nn.Flatten](https://docs.pytorch.org/docs/stable/generated/torch.nn.Flatten.html)</code> layer to transform the 2D feature map into a 1D vector.\n",
    ">        2. An <code>[nn.Linear](https://docs.pytorch.org/docs/stable/generated/torch.nn.Linear.html)</code> layer. You must calculate the correct number of input features. This depends on the output shape of the last `CNNBlock`. The output size of this layer should be **512**.\n",
    ">        3. An `nn.ReLU` activation.\n",
    ">        4. An <code>[nn.Dropout](https://docs.pytorch.org/docs/stable/generated/torch.nn.Dropout.html)</code> layer with a rate of `0.6` to help prevent overfitting.\n",
    ">        5. A final `nn.Linear` layer that maps the **512 features** to the **number of output classes**.\n",
    "\n",
    "**Inside the `forward` method**:\n",
    ">\n",
    ">    * Define the data flow through the network.\n",
    ">    * Pass the input `x` sequentially through `conv_block1`, then `conv_block2`, and then `conv_block3`.\n",
    ">    * Finally, pass the output of the last convolutional block through your `classifier`.\n",
    ">    * Return the final output.\n",
    "\n",
    "<details>\n",
    "<summary><b><font color=\"green\">Additional Code Hints (Click to expand if you are stuck)</font></b></summary>\n",
    "\n",
    "If you are stuck, here is a more detailed breakdown for the implementation.\n",
    "\n",
    "**For the `__init__` method**:\n",
    "\n",
    "* **Convolutional Blocks**:\n",
    ">    \n",
    "    * The first block is a straightforward instantiation: `self.conv_block1 = CNNBlock(in_channels=3, out_channels=32)`.\n",
    "    * For the second block, the `in_channels` must be `32` (the `out_channels` of the first). The `out_channels` will be `64`. Follow this pattern for the third block.\n",
    ">\n",
    "* **Classifier**:\n",
    "\n",
    "    * Start by defining the sequential container: `self.classifier = nn.Sequential(...)`\n",
    "    **1. Flatten Layer**: The first layer is `nn.Flatten()`. It takes no arguments.\n",
    "    **2. First Linear Layer**: This is `nn.Linear(in_features=..., out_features=512)`.\n",
    "        * To find the `in_features`, you need to calculate the size of the flattened tensor. The input images are 32x32. Each `CNNBlock` contains a `MaxPool2d` layer with a stride of 2, which halves the height and width. After three blocks, the dimensions will be `32 → 16 → 8 → 4`.\n",
    "        * The last `CNNBlock` outputs 128 channels. So, the total number of features is `128 * 4 * 4`.\n",
    "    **3. ReLU Layer**: Add `nn.ReLU()`.\n",
    "    **4. Dropout Layer**: Add `nn.Dropout(0.6)`.\n",
    "    **5. Final Linear Layer**: This is `nn.Linear(in_features=512, out_features=num_classes)`.\n",
    "\n",
    "**For the `forward` method**:\n",
    ">\n",
    "* This method describes how data flows from input to output. You can use the same variable `x` and reassign it after each step.\n",
    "* The pseudocode for the sequence is:\n",
    "    * `x = pass the input x through self.conv_block1`\n",
    "    * `x = pass the new x through self.conv_block2`\n",
    "    * `x = pass the new x through self.conv_block3`\n",
    "    * `x = pass the final feature map through self.classifier`\n",
    "* Finally, return `x`.\n",
    "\n",
    "</details>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77f6ffc6-60f8-4758-b193-6d02ee0c26e1",
   "metadata": {
    "deletable": false,
    "tags": [
     "graded"
    ]
   },
   "outputs": [],
   "source": [
    "# GRADED CLASS: SimpleCNN\n",
    "\n",
    "class SimpleCNN(nn.Module):\n",
    "    \"\"\"\n",
    "    Defines a simple CNN architecture using modular CNNBlocks.\n",
    "\n",
    "    This model stacks three reusable convolutional blocks followed by a fully\n",
    "    connected classifier to perform image classification.\n",
    "    \"\"\"\n",
    "    def __init__(self, num_classes):\n",
    "        \"\"\"\n",
    "        Initializes the layers of the SimpleCNN model.\n",
    "\n",
    "        Args:\n",
    "            num_classes (int): The number of output classes for the classifier.\n",
    "        \"\"\"\n",
    "        # Initialize the parent nn.Module class.\n",
    "        super(SimpleCNN, self).__init__()\n",
    "        \n",
    "        ### START CODE HERE ###\n",
    "\n",
    "        # Define the first convolutional block.\n",
    "        self.conv_block1 = __BLANK__\n",
    "        # Define the second convolutional block.\n",
    "        self.conv_block2 = __BLANK__\n",
    "        # Define the third convolutional block.\n",
    "        self.conv_block3 = __BLANK__\n",
    "\n",
    "        # Define the fully connected classifier block.\n",
    "        self.classifier = nn.Sequential(\n",
    "            # Flatten the 3D feature map (channels, height, width) into a 1D vector.\n",
    "            __BLANK__,\n",
    "            # First fully connected (linear) layer that maps the flattened features to a hidden layer.\n",
    "            __BLANK__,\n",
    "            # ReLU activation function to introduce non-linearity.\n",
    "            __BLANK__,\n",
    "            # Dropout layer to prevent overfitting by randomly setting a fraction of inputs to zero.\n",
    "            __BLANK__,\n",
    "            # Final fully connected (linear) layer that maps the hidden layer to the output classes.\n",
    "            __BLANK__\n",
    "        ) \n",
    "        \n",
    "        ### END CODE HERE ###\n",
    "\n",
    "    def forward(self, x):\n",
    "        \"\"\"\n",
    "        Defines the forward pass of the SimpleCNN model.\n",
    "\n",
    "        Args:\n",
    "            x (torch.Tensor): The input tensor containing a batch of images.\n",
    "\n",
    "        Returns:\n",
    "            torch.Tensor: The output tensor with logits for each class.\n",
    "        \"\"\"\n",
    "        \n",
    "        ### START CODE HERE ###\n",
    "        \n",
    "        # Pass the input through the first convolutional block.\n",
    "        x = __BLANK__\n",
    "        # Pass the result through the second convolutional block.\n",
    "        x = __BLANK__\n",
    "        # Pass the result through the third convolutional block.\n",
    "        x = __BLANK__\n",
    "\n",
    "        # Pass the final feature map through the classifier.\n",
    "        x = __BLANK__\n",
    "        \n",
    "        ### END CODE HERE ###\n",
    "        \n",
    "        # Return the final output tensor.\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "279e4cdd-f817-4e70-b13a-ec364107c0a6",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "# Verify the SimpleCNN\n",
    "print(\"--- Verifying SimpleCNN ---\\n\")\n",
    "\n",
    "# Verify the structure of the model\n",
    "# Instantiate the model with 15 output classes\n",
    "verify_simple_cnn = SimpleCNN(num_classes=15)\n",
    "print(\"Model Structure:\\n\")\n",
    "print(verify_simple_cnn)\n",
    "\n",
    "# Verify the output shape after a forward pass\n",
    "# Create a dummy input tensor (batch_size=64, channels=3, height=32, width=32)\n",
    "dummy_input = torch.randn(64, 3, 32, 32)\n",
    "print(f\"\\nInput tensor shape:  {dummy_input.shape}\")\n",
    "\n",
    "# Pass the dummy tensor through the model\n",
    "output = verify_simple_cnn(dummy_input)\n",
    "print(f\"Output tensor shape: {output.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af7fd6a0-c734-4dc0-8deb-1e076b8f20f8",
   "metadata": {},
   "source": [
    "#### Expected Output:\n",
    "\n",
    "```\n",
    "Model Structure:\n",
    "\n",
    "SimpleCNN(\n",
    "  (conv_block1): CNNBlock(\n",
    "    (block): Sequential(\n",
    "      (0): Conv2d(3, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
    "      (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
    "      (2): ReLU()\n",
    "      (3): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
    "    )\n",
    "  )\n",
    "  (conv_block2): CNNBlock(\n",
    "    (block): Sequential(\n",
    "      (0): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
    "      (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
    "      (2): ReLU()\n",
    "      (3): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
    "    )\n",
    "  )\n",
    "  (conv_block3): CNNBlock(\n",
    "    (block): Sequential(\n",
    "      (0): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
    "      (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
    "      (2): ReLU()\n",
    "      (3): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
    "    )\n",
    "  )\n",
    "  (classifier): Sequential(\n",
    "    (0): Flatten(start_dim=1, end_dim=-1)\n",
    "    (1): Linear(in_features=2048, out_features=512, bias=True)\n",
    "    (2): ReLU()\n",
    "    (3): Dropout(p=0.6, inplace=False)\n",
    "    (4): Linear(in_features=512, out_features=15, bias=True)\n",
    "  )\n",
    ")\n",
    "\n",
    "Input tensor shape:  torch.Size([64, 3, 32, 32])\n",
    "Output tensor shape: torch.Size([64, 15])\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6a9b977-bdd5-4eb2-84c6-ffd6a95ea1ad",
   "metadata": {
    "tags": []
   },
   "source": [
    "<br>\n",
    "\n",
    "**NOTE**: The test below evaluates your `SimpleCNN` class, which internally uses the `CNNBlock` you implemented in the previous exercise. If you did not pass the test for `Exercise 2 - CNNBlock`, running the following cell will likely return an error. Please make sure your `CNNBlock` implementation is correct first!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "290f8ef1-40c7-403e-bbf4-add10dbc56ad",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "# Test your code!\n",
    "unittests.exercise_3(SimpleCNN, CNNBlock)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73799749-5253-4867-96a6-dd311e39e2f4",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "With your `SimpleCNN` class defined, the next step is to create an instance of the model.\n",
    "\n",
    "* First, dynamically determine the number of classes by getting the length of the `.classes` attribute from your `train_dataset`.\n",
    "* Next, create an instance of your `SimpleCNN` model, passing the `num_classes` variable to its constructor. This ensures the final layer of your model is correctly sized for your 15-class problem."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e70233b-fbfe-4379-9a51-202e10740cec",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "# Get the number of classes\n",
    "num_classes = len(train_dataset.classes)\n",
    "\n",
    "# Instantiate the model\n",
    "model = SimpleCNN(num_classes)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd77a33d-ac4d-4a8d-ad62-992ff1e7f086",
   "metadata": {},
   "source": [
    "<a name='3'></a>\n",
    "## 3 - Training the Upgraded Model\n",
    "With your upgraded data pipeline and modular CNN architecture complete, you are ready to begin the training process. In this section, you will configure the final pieces of your training pipeline: the loss function and the optimizer. Then, you will implement the core training and validation logic that will run your experiment and reveal how well your new model performs.\n",
    "\n",
    "<a name='3-1'></a>\n",
    "### 3.1 - Configuring the Loss and Optimizer\n",
    "\n",
    "Before you can train the model, you must define two key components: a loss function to measure error and an optimizer to update the model's weights.\n",
    "\n",
    "* For the loss function, you will continue to use `nn.CrossEntropyLoss`, the standard choice for multi-class classification.\n",
    ">\n",
    "* For the optimizer, you will use `Adam`, but with an important addition to combat overfitting: `weight_decay`. \n",
    "    * Weight decay adds a penalty to the loss function based on the magnitude of the model's weights. It encourages the network to learn smaller, simpler weight values, which makes it more robust and less likely to memorize the training data. This is another vital tool for improving your model's ability to generalize."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f85ea397-ac90-40dc-ba0d-0d3a13998de4",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "# Loss function\n",
    "loss_function = nn.CrossEntropyLoss()\n",
    "\n",
    "# Optimizer for the model with weight_decay\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.0005, weight_decay=0.0005)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e693122-118a-4a43-84c6-cfbc7457d5e2",
   "metadata": {},
   "source": [
    "<a name='3-2'></a>\n",
    "### 3.2 - Implementing the Training and Validation Logic\n",
    "\n",
    "You will now implement the core logic for training and evaluating your model. This will be done in two separate functions:\n",
    "\n",
    "* `train_epoch`: To perform a single pass over the training data to update the model.\n",
    "* `validate_epoch`: To perform a single pass over the validation data to measure performance.\n",
    "\n",
    "<a name='ex-4'></a>\n",
    "### Exercise 4 -  train_epoch\n",
    "\n",
    "Your task is to complete the core training logic within the `for` loop of the `train_epoch` function. You will implement the five fundamental steps of a single training iteration.\n",
    "\n",
    "**Your Task**:\n",
    "\n",
    "Inside the `train_epoch` function, for each batch of `images` and `labels`:\n",
    "\n",
    "* **Clear Gradients**: \n",
    "    * Before computing the gradients for the current batch, you must clear any gradients that were stored from the previous batch.\n",
    "* **Forward Pass**: \n",
    "    * Feed the `images` through the `model` to get the output predictions.\n",
    "* **Calculate Loss**: \n",
    "    * Use the provided `loss_function` to measure the difference between the model's `outputs` and the true `labels`.\n",
    "* **Backward Pass**: \n",
    "    * Compute the gradients of the loss with respect to all the model's parameters. This is also known as backpropagation.\n",
    "* **Update Parameters**: \n",
    "    * Use the `optimizer` to adjust the model's parameters based on the gradients you just computed.\n",
    "\n",
    "<details>\n",
    "<summary><b><font color=\"green\">Additional Code Hints (Click to expand if you are stuck)</font></b></summary>\n",
    "\n",
    "If you need some help, here is a more direct guide for each step.\n",
    "\n",
    "* **Clear Gradients**: This is done to prevent the accumulation of gradients across batches.\n",
    "    * The pseudocode is: `call the zero_grad() method on the optimizer`.\n",
    ">\n",
    "* **Forward Pass**: This is how you get the model's predictions for the current batch.\n",
    "    * The pseudocode is: `outputs = call the model, passing the images as the argument`.\n",
    ">\n",
    "* **Calculate Loss**: You compare the model's predictions with the actual ground truth labels.\n",
    "    * The pseudocode is: `loss = call the loss_function, passing the outputs and labels as arguments`.\n",
    ">\n",
    "* **Backward Pass**: This step calculates how much each model parameter contributed to the overall loss.\n",
    "    * The pseudocode is: `call the backward() method on the loss tensor`.\n",
    ">    \n",
    "* **Update Parameters**: The optimizer uses the calculated gradients to take a small step in the direction that minimizes the loss.\n",
    "    * The pseudocode is: `call the step() method on the optimizer`.\n",
    "\n",
    "</details>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "677d45c3-298b-4d4f-bb07-21efcb53c526",
   "metadata": {
    "deletable": false,
    "tags": [
     "graded"
    ]
   },
   "outputs": [],
   "source": [
    "# GRADED FUNCTION: train_epoch\n",
    "\n",
    "def train_epoch(model, train_loader, loss_function, optimizer, device):\n",
    "    \"\"\"\n",
    "    Performs a single training epoch.\n",
    "\n",
    "    Args:\n",
    "        model (torch.nn.Module): The neural network model to train.\n",
    "        train_loader (torch.utils.data.DataLoader): The DataLoader for the training data.\n",
    "        loss_function (callable): The loss function.\n",
    "        optimizer (torch.optim.Optimizer): The optimizer.\n",
    "        device (torch.device): The device (CPU or GPU) to perform training on.\n",
    "\n",
    "    Returns:\n",
    "        float: The average training loss for the epoch.\n",
    "    \"\"\"\n",
    "    # Set the model to training mode\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    # Iterate over batches of data in the training loader\n",
    "    for images, labels in train_loader:\n",
    "        # Move images and labels to the specified device\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "        \n",
    "        ### START CODE HERE ###\n",
    "        \n",
    "        # Clear the gradients of all optimized variables\n",
    "        __BLANK__\n",
    "        # Perform a forward pass to get model outputs\n",
    "        __BLANK__\n",
    "        # Calculate the loss\n",
    "        __BLANK__\n",
    "        # Perform a backward pass to compute gradients\n",
    "        __BLANK__\n",
    "        # Update the model parameters\n",
    "        __BLANK__\n",
    "        \n",
    "        ### END CODE HERE ###\n",
    "        \n",
    "        # Accumulate the training loss for the batch\n",
    "        running_loss += loss.item() * images.size(0)\n",
    "        \n",
    "    # Calculate and return the average training loss for the epoch\n",
    "    epoch_loss = running_loss / len(train_loader.dataset)\n",
    "    return epoch_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "865482be-7a13-40e1-a5d0-423ce72c6039",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "# Use a helper function to perform a sanity check on the train_epoch implementation\n",
    "helper_utils.verify_training_process(SimpleCNN, train_loader, loss_function, train_epoch, device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "171df88c-ef49-498c-9e69-dd22e3497822",
   "metadata": {},
   "source": [
    "#### Expected Output (Approximately):\n",
    "\n",
    "```\n",
    "Training on 640 images for 5 epochs:\n",
    "\n",
    "Epoch [1/5], Loss: 2.6735\n",
    "Epoch [2/5], Loss: 2.3238\n",
    "Epoch [3/5], Loss: 2.0528\n",
    "Epoch [4/5], Loss: 1.8341\n",
    "Epoch [5/5], Loss: 1.7676\n",
    "\n",
    "Weight Update Check:\tModel weights changed during training.\n",
    "Loss Trend Check:\tLoss decreased from 2.6735 to 1.7676.\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b341c2e8-d4ec-49a3-a8d6-fd4c557ac954",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "# Test your code!\n",
    "unittests.exercise_4(train_epoch)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1bcfdcd6-5937-48a2-b27a-434e6e23ffc9",
   "metadata": {},
   "source": [
    "<a name='ex-5'></a>\n",
    "### Exercise 5 - validate_epoch\n",
    "\n",
    "Your task is to complete the validation logic. This involves performing a forward pass and then calculating both the loss and the number of correct predictions to determine the accuracy.\n",
    "\n",
    "**Your Task**:\n",
    "\n",
    "* **Disable Gradient Calculation**:\n",
    ">\n",
    "    * Wrap the entire for loop within the `torch.no_grad()` context manager. This tells PyTorch not to compute gradients, which saves memory and computation time during validation.\n",
    ">\n",
    "* **Inside the `for` loop**:\n",
    ">\n",
    "    * **Forward Pass**: \n",
    "        * Just like in training, pass the `images` through the `model` to get its `outputs`.        \n",
    "    * **Calculate Loss**: \n",
    "        * Use the `loss_function` to compute the `val_loss` between the `outputs` and the true `labels`.\n",
    "    * **Accumulate Loss**: \n",
    "        * Add the batch's loss to the `running_val_loss`. Remember to get the scalar value from the loss tensor and scale it by the batch size.\n",
    "    * **Get Predictions**: \n",
    "        * Determine the model's predicted class for each image in the batch. The `outputs` from your model are raw scores (logits). The class with the highest score is the model's prediction. You need to find the index of this maximum score.\n",
    "\n",
    "<details>\n",
    "<summary><b><font color=\"green\">Additional Code Hints (Click to expand if you are stuck)</font></b></summary>\n",
    "\n",
    "If you need a bit more direction, here is a detailed guide.\n",
    "\n",
    "**Disable Gradient Calculation**:\n",
    ">\n",
    "This is a context manager in PyTorch. The structure you need is `with torch.no_grad()`:. The for loop should be indented inside this block.\n",
    "\n",
    "**Inside the for loop**:\n",
    "   \n",
    "* **Forward Pass**: This is identical to the training loop. The pseudocode is: `outputs = call the model, passing the images as the argument`.\n",
    "\n",
    "* **Calculate Loss**: This is also the same as in the training loop. The pseudocode is: `val_loss = call the loss_function, passing the outputs and labels as arguments`.\n",
    "\n",
    "* **Accumulate Loss**: You need to update the `running_val_loss`. The pseudocode is: `running_val_loss += get the scalar value of val_loss using the .item() method * the number of images in the current batch`.\n",
    "\n",
    "* **Get Predictions**: You need to find the most likely class from the output logits.\n",
    "\n",
    "    * The `torch.max()` function is perfect for this. You need to call it on the `outputs` tensor along dimension 1 (the class dimension).\n",
    "\n",
    "    * The pseudocode is: `_, predicted = use torch.max() on the outputs tensor, specifying dimension 1`.\n",
    "\n",
    "    * Note that `torch.max()` returns a tuple of (max_values, max_indices). You only need the second element, the indices, which correspond to the predicted class labels.\n",
    "\n",
    "</details>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a298e2fa-2676-4278-aded-195ece701f50",
   "metadata": {
    "deletable": false,
    "tags": [
     "graded"
    ]
   },
   "outputs": [],
   "source": [
    "# GRADED FUNCTION: validate_epoch\n",
    "\n",
    "def validate_epoch(model, val_loader, loss_function, device):\n",
    "    \"\"\"\n",
    "    Performs a single validation epoch.\n",
    "\n",
    "    Args:\n",
    "        model (torch.nn.Module): The neural network model to validate.\n",
    "        val_loader (torch.utils.data.DataLoader): The DataLoader for the validation data.\n",
    "        loss_function (callable): The loss function.\n",
    "        device (torch.device): The device (CPU or GPU) to perform validation on.\n",
    "\n",
    "    Returns:\n",
    "        tuple: A tuple containing the average validation loss and validation accuracy.\n",
    "    \"\"\"\n",
    "    # Set the model to evaluation mode\n",
    "    model.eval()\n",
    "    running_val_loss = 0.0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    \n",
    "    ### START CODE HERE ###\n",
    "    \n",
    "    # Disable gradient calculations for validation\n",
    "    __BLANK__:\n",
    "        \n",
    "    ### END CODE HERE ###\n",
    "    \n",
    "        # Iterate over batches of data in the validation loader\n",
    "        for images, labels in val_loader:\n",
    "            # Move images and labels to the specified device\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "            \n",
    "            ### START CODE HERE ###\n",
    "            \n",
    "            # Perform a forward pass to get model outputs\n",
    "            outputs = __BLANK__\n",
    "            \n",
    "            # Calculate the validation loss for the batch\n",
    "            val_loss = __BLANK__\n",
    "            # Accumulate the validation loss\n",
    "            running_val_loss += __BLANK__\n",
    "            \n",
    "            # Get the predicted class labels\n",
    "            _, predicted = __BLANK__\n",
    "            \n",
    "            ### END CODE HERE ###\n",
    "            \n",
    "            # Update the total number of samples\n",
    "            total += labels.size(0)\n",
    "            # Update the number of correct predictions\n",
    "            correct += (predicted == labels).sum().item()\n",
    "            \n",
    "    # Calculate the average validation loss and accuracy for the epoch\n",
    "    epoch_val_loss = running_val_loss / len(val_loader.dataset)\n",
    "    epoch_accuracy = 100.0 * correct / total\n",
    "    \n",
    "    return epoch_val_loss, epoch_accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd09fa81-c19e-42d7-8e57-1f5115ce07b3",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "# Use a helper function to perform a sanity check on the validate_epoch implementation\n",
    "helper_utils.verify_validation_process(SimpleCNN, val_loader, loss_function, validate_epoch, device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "806cb5ef-efcd-4ca8-b4bf-c6fcd92b7fc2",
   "metadata": {},
   "source": [
    "#### Expected Output:\n",
    "\n",
    "```\n",
    "Return Types Check:\tFunction returned a float for loss and accuracy.\n",
    "Weight Integrity Check:\tModel weights were not changed during validation.\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2db780b-ccec-430d-86a1-32da4e685ece",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "# Test your code!\n",
    "unittests.exercise_5(validate_epoch)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4fc388c-da11-4823-a8cd-0cd15b521530",
   "metadata": {},
   "source": [
    "---\n",
    "# Submission Note\n",
    "\n",
    "Congratulations! You've completed the final graded exercise of this assignment.\n",
    "\n",
    "If you've successfully passed all the unit tests above, you've completed the core requirements of this assignment.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d45a6f04-4ce1-4056-bb89-8de3baac6c4d",
   "metadata": {},
   "source": [
    "With the individual functions for training and validation complete, you can now bring them together in the main `training_loop`. This function orchestrates the entire training process over a set number of epochs and includes a pivotal upgrade.\n",
    "\n",
    "A common challenge is that a model's performance can peak and then decline if training continues for too long. To address this, the `training_loop` will:\n",
    "\n",
    "* **Monitor** the validation accuracy at the end of each epoch.\n",
    "* **Keep track** of the best performing model state seen so far.\n",
    "* After the final epoch, it automatically **returns the model from its single best epoch**.\n",
    "\n",
    "This guarantees that you always get back the version of your model that achieved the highest validation accuracy during the entire training run."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05cd7b0a-1435-45f2-a03a-1e0240f238fb",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "def training_loop(model, train_loader, val_loader, loss_function, optimizer, num_epochs, device):\n",
    "    \"\"\"\n",
    "    Trains and validates a PyTorch neural network model.\n",
    "\n",
    "    Args:\n",
    "        model (torch.nn.Module): The model to be trained.\n",
    "        train_loader (torch.utils.data.DataLoader): DataLoader for the training set.\n",
    "        val_loader (torch.utils.data.DataLoader): DataLoader for the validation set.\n",
    "        loss_function (callable): The loss function.\n",
    "        optimizer (torch.optim.Optimizer): The optimization algorithm.\n",
    "        num_epochs (int): The total number of epochs to train for.\n",
    "        device (torch.device): The device (e.g., 'cuda' or 'cpu') to run training on.\n",
    "\n",
    "    Returns:\n",
    "        tuple: A tuple containing the best trained model and a list of metrics\n",
    "               (train_losses, val_losses, val_accuracies).\n",
    "    \"\"\"\n",
    "    # Move the model to the specified device (CPU or GPU)\n",
    "    model.to(device)\n",
    "    \n",
    "    # Initialize variables to track the best performing model\n",
    "    best_val_accuracy = 0.0\n",
    "    best_model_state = None\n",
    "    best_epoch = 0\n",
    "    \n",
    "    # Initialize lists to store training and validation metrics\n",
    "    train_losses, val_losses, val_accuracies = [], [], []\n",
    "    \n",
    "    print(\"--- Training Started ---\")\n",
    "    \n",
    "    # Loop over the specified number of epochs\n",
    "    for epoch in range(num_epochs):\n",
    "        # Perform one epoch of training\n",
    "        epoch_loss = train_epoch(model, train_loader, loss_function, optimizer, device)\n",
    "        train_losses.append(epoch_loss)\n",
    "        \n",
    "        # Perform one epoch of validation\n",
    "        epoch_val_loss, epoch_accuracy = validate_epoch(model, val_loader, loss_function, device)\n",
    "        val_losses.append(epoch_val_loss)\n",
    "        val_accuracies.append(epoch_accuracy)\n",
    "        \n",
    "        # Print the metrics for the current epoch\n",
    "        print(f\"Epoch [{epoch+1}/{num_epochs}], Train Loss: {epoch_loss:.4f}, Val Loss: {epoch_val_loss:.4f}, Val Accuracy: {epoch_accuracy:.2f}%\")\n",
    "        \n",
    "        # Check if the current model is the best one so far\n",
    "        if epoch_accuracy > best_val_accuracy:\n",
    "            best_val_accuracy = epoch_accuracy\n",
    "            best_epoch = epoch + 1\n",
    "            # Save the state of the best model in memory\n",
    "            best_model_state = copy.deepcopy(model.state_dict())\n",
    "            \n",
    "    print(\"--- Finished Training ---\")\n",
    "    \n",
    "    # Load the best model weights before returning\n",
    "    if best_model_state:\n",
    "        print(f\"\\n--- Returning best model with {best_val_accuracy:.2f}% validation accuracy, achieved at epoch {best_epoch} ---\")\n",
    "        model.load_state_dict(best_model_state)\n",
    "    \n",
    "    # Consolidate all metrics into a single list\n",
    "    metrics = [train_losses, val_losses, val_accuracies]\n",
    "    \n",
    "    # Return the trained model and the collected metrics\n",
    "    return model, metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72f3d5d0-9266-46c1-b113-821332732574",
   "metadata": {},
   "source": [
    "Everything is now in place. The following code will call your `training_loop` function to kick off the full training and validation process.\n",
    "\n",
    "The model will train for **50 epochs**. With the powerful regularization techniques you have added (Batch Normalization, increased Dropout, and Weight Decay) and a smaller learning rate, the model is designed to learn more cautiously. This longer training run gives the model sufficient time to converge to a robust, generalized solution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c4ed632-494b-4368-a476-499a89e3d921",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "# Start the training process by calling the training loop function\n",
    "trained_model, training_metrics = training_loop(\n",
    "    model=model, \n",
    "    train_loader=train_loader, \n",
    "    val_loader=val_loader, \n",
    "    loss_function=loss_function, \n",
    "    optimizer=optimizer, \n",
    "    num_epochs=50, \n",
    "    device=device\n",
    ")\n",
    "\n",
    "# Visualize the training metrics (loss and accuracy)\n",
    "print(\"\\n--- Training Plots ---\\n\")\n",
    "helper_utils.plot_training_metrics(training_metrics)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "304397a3-f66a-4ec1-8618-cdadd9e2513b",
   "metadata": {},
   "source": [
    "**Analyzing the Results**\n",
    "\n",
    "Take a close look at the new training plots and compare them to the ones from the previous lab. The difference is remarkable.\n",
    "\n",
    "The training and validation loss curves now follow each other very closely, and the wide gap that signaled overfitting is gone. The validation accuracy shows a much healthier, more consistent climb. This is clear evidence that you have successfully solved the overfitting problem! The combination of more data augmentation, Batch Normalization, and Weight Decay worked together to create a model that generalizes far better than before.\n",
    "\n",
    "**The Performance Plateau**\n",
    "\n",
    "Your model's validation accuracy now peaks somewhere around 70%, which is a solid result. You might wonder, however, why it did not achieve 90% or higher, especially with all these advanced techniques and longer training. The answer lies in how effectively you have used the tools available to you.\n",
    "\n",
    "The fundamentals you have learned in this course provide a solid foundation for building deep learning models. The techniques now at your disposal, from data augmentation to modular design and regularization, are powerful. Applying them correctly is precisely what allowed you to solve the initial overfitting problem and achieve this strong result. This demonstrates that you are pushing the limits of what can be accomplished with this foundational toolkit.\n",
    "\n",
    "You have achieved something significant. You started by building a simple CNN that suffered from a common and challenging problem, and you systematically upgraded your entire pipeline with professional techniques to create this final, robust model. Congratulations on a successful result!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "887a2671-062f-484e-a1fb-1d77e7d99520",
   "metadata": {},
   "source": [
    "<a name='4'></a>\n",
    "## 4 - Beyond the Foundations: A Glimpse into the Next Level\n",
    "\n",
    "You have successfully taken a simple CNN, diagnosed its flaws, and systematically upgraded it into a robust, well-generalized model. You have pushed the foundational toolkit you've learned to its limits to achieve a strong result.\n",
    "\n",
    "**But what if this isn't the limit? What if there was another way?**\n",
    "\n",
    "**What if you could take your model's accuracy from around 70% to over 80% on this exact same dataset?**\n",
    "\n",
    "Take a look at the results from a different, more powerful training strategy. Run the next cell to see that in action."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0dc717c9-7c50-4c32-8cad-df2d907eb7f1",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "# Import the preview function that demonstrates concepts from the next course\n",
    "from c2_preview.c2_preview import course_2_preview\n",
    "\n",
    "# This helper function runs a training loop using a powerful strategy that will be taught\n",
    "# in the next course. Run this cell to see the improved results in action.\n",
    "trained_model = course_2_preview(\n",
    "    train_dataset, \n",
    "    val_dataset, \n",
    "    loss_function,\n",
    "    device,\n",
    "    num_epochs=5\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21517cc2-f6a6-4e16-93c9-bb58e8d79f68",
   "metadata": {
    "tags": []
   },
   "source": [
    "<br>\n",
    "\n",
    "Incredible, right? In just **5 epochs**, the validation accuracy soared past 80%, a level of performance your previous model did not reach even after 50 epochs.\n",
    "\n",
    "**How is such a rapid and dramatic improvement possible on the exact same data?**\n",
    "\n",
    "This result was achieved by combining several powerful, next-level techniques that you will master in the upcoming course. This was just a preview, but the strategy involved three key upgrades:\n",
    "\n",
    "* **Using a Pre-trained Model**: This is the most significant change. Instead of starting from scratch with random weights, this approach uses a sophisticated model that has already been trained on millions of images. It already possesses a deep understanding of visual patterns, which you can then fine-tune for your specific task.\n",
    "\n",
    "* **Dynamic Learning Rate Scheduling**: Rather than using a single, fixed learning rate, this strategy uses a *learning rate scheduler*. This tool intelligently adjusts the learning rate during training, making larger updates at the beginning and smaller, more precise adjustments as the model gets closer to the best solution.\n",
    "\n",
    "* **More Advanced Transformations**: The data augmentation pipeline used for this preview was also more advanced. It included techniques tailored specifically for these high performance models, ensuring the network learned from a richer and more challenging set of training examples.\n",
    "\n",
    "These concepts are just a glimpse of what comes next. You have built an incredible foundation, and now you are ready to learn the strategies that professionals use to achieve state of the art results quickly and efficiently.\n",
    "\n",
    "## Conclusion\n",
    "\n",
    "Congratulations on completing this assignment!\n",
    "\n",
    "You have successfully navigated a complete and realistic machine learning workflow. You began with a model that suffered from overfitting, diagnosed the problem, and then systematically applied a series of powerful, professional techniques to solve it. You have not just improved a model; you have learned a repeatable process for refining and strengthening any neural network you build in the future.\n",
    "\n",
    "The skills you practiced here, modular design, implementing regularization, and analyzing training dynamics, are fundamental to building effective deep learning models. You have moved beyond the basics and are now equipped with the practical knowledge needed to tackle more complex, real world problems. Well done!"
   ]
  }
 ],
 "metadata": {
  "grader_version": "1",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
